{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1de3ef734af54e9084ba6d24ad2b9573":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_66631f3e7c72429f8d5d5145f3158676","IPY_MODEL_81011b5150904e2fa994ae7deeb8edae","IPY_MODEL_e5eff094c0644c69ad9e5d3a31a3f452","IPY_MODEL_9c9f7251c0e941e7a63f7f9a8323cfa9","IPY_MODEL_8f1e4282e29643ed8225f2bf1028056f"],"layout":"IPY_MODEL_eda9f24f0ff243cfbd6878a75e927d07"}},"66631f3e7c72429f8d5d5145f3158676":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85baed07f8c94ed196c374a6e58e22cc","placeholder":"​","style":"IPY_MODEL_fcf7279ba53b440abe3896b38ef0cc6f","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"81011b5150904e2fa994ae7deeb8edae":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_31d82894dc4a4f8b927e78d00950e39b","placeholder":"​","style":"IPY_MODEL_c55401d4c2c04e7698935c9d8c763355","value":""}},"e5eff094c0644c69ad9e5d3a31a3f452":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_c5d3dd1626674485b1665c78e64d7510","style":"IPY_MODEL_0a13584b9f134dfa97ca691f8eddd434","value":true}},"9c9f7251c0e941e7a63f7f9a8323cfa9":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_5e5be5a0971640c7b2391691f809da88","style":"IPY_MODEL_6e45ce4dc1c145468284c1c8c0ec6939","tooltip":""}},"8f1e4282e29643ed8225f2bf1028056f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37b872d373cc48bb994ab6d312557c13","placeholder":"​","style":"IPY_MODEL_90763fb40fda44dba79088228c7808e0","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"eda9f24f0ff243cfbd6878a75e927d07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"85baed07f8c94ed196c374a6e58e22cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcf7279ba53b440abe3896b38ef0cc6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31d82894dc4a4f8b927e78d00950e39b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c55401d4c2c04e7698935c9d8c763355":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5d3dd1626674485b1665c78e64d7510":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a13584b9f134dfa97ca691f8eddd434":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e5be5a0971640c7b2391691f809da88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e45ce4dc1c145468284c1c8c0ec6939":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"37b872d373cc48bb994ab6d312557c13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90763fb40fda44dba79088228c7808e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"210483cad01847e58be29f530e5ee8cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e56946c90214f27a89a16113cea861d","IPY_MODEL_5417a60f28be450a8cc7938dfa12e0a2","IPY_MODEL_46e7cba5323643189a971b32fd0bb809"],"layout":"IPY_MODEL_a9adb03db8d04ce9852e852d40cd841f"}},"4e56946c90214f27a89a16113cea861d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd8ddd6f20114f3d8b09b872d27cbc60","placeholder":"​","style":"IPY_MODEL_b4831d3b79f449d89495fc7f11f4df93","value":"100%"}},"5417a60f28be450a8cc7938dfa12e0a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bc1ba4b9d2345a98a594a4b05dbc293","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba6675b2cea34a0c8cb08a39f2844d40","value":3}},"46e7cba5323643189a971b32fd0bb809":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32d5648aa6e44e0e96929fc91fc999d5","placeholder":"​","style":"IPY_MODEL_7ba70446b54341ccb46d9cb5cc3f4105","value":" 3/3 [00:00&lt;00:00,  9.61it/s]"}},"a9adb03db8d04ce9852e852d40cd841f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd8ddd6f20114f3d8b09b872d27cbc60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4831d3b79f449d89495fc7f11f4df93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bc1ba4b9d2345a98a594a4b05dbc293":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba6675b2cea34a0c8cb08a39f2844d40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"32d5648aa6e44e0e96929fc91fc999d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ba70446b54341ccb46d9cb5cc3f4105":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4983fb7c2cca461fb5539e73cccd6ac7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec953004e4534ac68da1efba05da22b2","IPY_MODEL_fe72c604335b42d895dd3ce73348a057","IPY_MODEL_86149739912d4bf7a46949063be7b2bc"],"layout":"IPY_MODEL_10f1b68b08f141a8bcbd55adab4e7821"}},"ec953004e4534ac68da1efba05da22b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2925e1f42b04317a660d91d4f622fce","placeholder":"​","style":"IPY_MODEL_b984373baa084d959c74f810100f3a67","value":"100%"}},"fe72c604335b42d895dd3ce73348a057":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9149d8e855694b8294debd55b71a53d1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16ed605b5cb441758581fe9c80ffac1d","value":1}},"86149739912d4bf7a46949063be7b2bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dae63d1f4fb4c8c89725b2d7a8d5f51","placeholder":"​","style":"IPY_MODEL_a222ab21d8c04314918778412ac91e77","value":" 1/1 [00:00&lt;00:00,  8.14it/s]"}},"10f1b68b08f141a8bcbd55adab4e7821":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2925e1f42b04317a660d91d4f622fce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b984373baa084d959c74f810100f3a67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9149d8e855694b8294debd55b71a53d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16ed605b5cb441758581fe9c80ffac1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7dae63d1f4fb4c8c89725b2d7a8d5f51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a222ab21d8c04314918778412ac91e77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7a7c5b5d3954a9a88afa445a764775e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be445e67b10a4a3a9a0ceb0cf30b992c","IPY_MODEL_7731aa1959d54966baf4406c1a8ba863","IPY_MODEL_aaaa912e8aa54fca8ab1ba751364d44d"],"layout":"IPY_MODEL_52eca921fef44509859239976ff5ee14"}},"be445e67b10a4a3a9a0ceb0cf30b992c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94b183957bc34dc588cd1af085ec3122","placeholder":"​","style":"IPY_MODEL_56081959adc640dcb950f256e7609e2d","value":"Downloading pytorch_model.bin: 100%"}},"7731aa1959d54966baf4406c1a8ba863":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdfac8d378cf4b798fa96f86e774352e","max":267967963,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df322d52719d488f876cf17980127ac6","value":267967963}},"aaaa912e8aa54fca8ab1ba751364d44d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b14176a574de4bae9562599ca1498ae8","placeholder":"​","style":"IPY_MODEL_5ed7c4e1f7304e26b074831a63c7b7e7","value":" 268M/268M [00:01&lt;00:00, 187MB/s]"}},"52eca921fef44509859239976ff5ee14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94b183957bc34dc588cd1af085ec3122":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56081959adc640dcb950f256e7609e2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdfac8d378cf4b798fa96f86e774352e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df322d52719d488f876cf17980127ac6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b14176a574de4bae9562599ca1498ae8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ed7c4e1f7304e26b074831a63c7b7e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Notebook objectives:\n","- Fine-tune a HuggingFace model for text classification by following this documentation. Below are the specifications:\n","  - Make use of Google Colab’s free GPU to train a HuggingFace model\n","  - Follow the documentation from start to finish\n","  - Be able to answer questions about each piece of code during the interview\n","  - Demonstrate fine-tuning using the sample dataset provided.\n","  - Bonus points: Use another text classification dataset to perform fine-tuning\n"],"metadata":{"id":"pREHsp2nss1m"}},{"cell_type":"markdown","source":["\n","# Project 1: Text classification\n","\n","## Project objective\n","- Fine-tune a HuggingFace model for text classification \n","\n","## Set up install the following:\n","- transformers: model used for text classification\n","- dataset: library to download GLUE datasets\n","- Git-LFS\n","\n","-  using  a pre trained SST-2 (Standford Sentiment Analysis Treebank) that determines  if a sentence is positive or neative\n","\n","- using [hate-speech-data](https://huggingface.co/datasets/hate_speech_offensive) to finetune the model to predict if the text is hate speech\n","\n","Objecttive for part 2:\n","- Social media and messaging platforms have given us the ability to connect and express ourselves freely. However, what happens when these platforms are used to spread negativity and hate? \n","- That's where the Hater_classifier comes in. This tool is designed to identify hateful speech on social media, possibly filtering out the negativity making it a powerful tool for creating a more positive online environment.\n","\n"],"metadata":{"id":"TLZA46rtupEN"}},{"cell_type":"code","source":["! pip install  transformers\n","! apt install git-lfs\n","! pip install datasets\n","! pip install torch\n","! pip install imbalanced-learn\n","! pip install optuna\n","! pip install ray[tune]\n","! pip install sklearn\n","! pip install pynvml "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BqM4I0S_upQq","executionInfo":{"status":"ok","timestamp":1679669685395,"user_tz":-480,"elapsed":67659,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"d5fde3fe-279b-4ec0-fb40-a8c15d2b975f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Reading package lists... Done\n","Building dependency tree       \n","\n","git-lfs is already the newest version (2.9.2-1).\n","0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.10.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.9/dist-packages (0.10.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.22.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.10.1)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: optuna in /usr/local/lib/python3.9/dist-packages (3.1.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n","Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from optuna) (0.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.47)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.10.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.9/dist-packages (from optuna) (6.7.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ray[tune] in /usr/local/lib/python3.9/dist-packages (2.3.0)\n","Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (20.21.0)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (1.22.4)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (4.3.3)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (8.1.3)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (1.3.1)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (22.2.0)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (1.3.3)\n","Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (1.51.3)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (1.0.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (2.27.1)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (3.19.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (3.10.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (1.4.4)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (0.8.10)\n","Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.9/dist-packages (from ray[tune]) (2.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorboardX>=1.9->ray[tune]) (23.0)\n","Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.9/dist-packages (from virtualenv>=20.0.24->ray[tune]) (3.1.1)\n","Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.9/dist-packages (from virtualenv>=20.0.24->ray[tune]) (0.3.6)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->ray[tune]) (0.19.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->ray[tune]) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->ray[tune]) (2.8.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->ray[tune]) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->ray[tune]) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->ray[tune]) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->ray[tune]) (1.26.15)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->ray[tune]) (1.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.9/dist-packages (0.0.post1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pynvml in /usr/local/lib/python3.9/dist-packages (11.5.0)\n"]}]},{"cell_type":"markdown","source":["import all the libraries needed"],"metadata":{"id":"oL12MX3HDMag"}},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","import pandas as pd\n","import torch\n","# import datasets\n","from datasets import load_dataset, load_metric, Dataset, DatasetDict\n","# from transformers import AutoTokenizer\n","import transformers\n","from transformers import AutoTokenizer,Trainer,AutoModelForSequenceClassification, TrainingArguments\n","from transformers.utils import send_example_telemetry\n","# import imblearn\n","from imblearn.over_sampling import RandomOverSampler\n","from imblearn.under_sampling import RandomUnderSampler\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","\n","# for gpu util\n","from pynvml import * \n","\n"],"metadata":{"id":"PawQaIib6XE0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["define functions to track GPU utilization"],"metadata":{"id":"VLV6LolAL14f"}},{"cell_type":"code","source":["from pynvml import *\n","\n","\n","def print_gpu_utilization():\n","    nvmlInit()\n","    handle = nvmlDeviceGetHandleByIndex(0)\n","    info = nvmlDeviceGetMemoryInfo(handle)\n","    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n","\n","\n","def print_summary(result):\n","    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n","    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n","    print_gpu_utilization()\n"],"metadata":{"id":"fimrPAgmL2Fd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Get your hugging face api in https://huggingface.co/settings/tokens"],"metadata":{"id":"ZqJ6okqIMlkR"}},{"cell_type":"code","source":["# log in ito  hugging face\n","notebook_login()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":416,"referenced_widgets":["1de3ef734af54e9084ba6d24ad2b9573","66631f3e7c72429f8d5d5145f3158676","81011b5150904e2fa994ae7deeb8edae","e5eff094c0644c69ad9e5d3a31a3f452","9c9f7251c0e941e7a63f7f9a8323cfa9","8f1e4282e29643ed8225f2bf1028056f","eda9f24f0ff243cfbd6878a75e927d07","85baed07f8c94ed196c374a6e58e22cc","fcf7279ba53b440abe3896b38ef0cc6f","31d82894dc4a4f8b927e78d00950e39b","c55401d4c2c04e7698935c9d8c763355","c5d3dd1626674485b1665c78e64d7510","0a13584b9f134dfa97ca691f8eddd434","5e5be5a0971640c7b2391691f809da88","6e45ce4dc1c145468284c1c8c0ec6939","37b872d373cc48bb994ab6d312557c13","90763fb40fda44dba79088228c7808e0"]},"id":"d5VYN9dkvUA9","executionInfo":{"status":"ok","timestamp":1679669714738,"user_tz":-480,"elapsed":3,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"3c7f2c08-d274-4322-aa82-950c239e5051"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1de3ef734af54e9084ba6d24ad2b9573"}},"metadata":{}}]},{"cell_type":"code","source":["# show the version on the tranformer\n","# since transform is > 4.11.0 there is no issue\n","print(transformers.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LF7NkEKvvidQ","executionInfo":{"status":"ok","timestamp":1679669718190,"user_tz":-480,"elapsed":1023,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"c3ab01e3-9bd2-4933-9e70-793f49931670"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4.27.3\n"]}]},{"cell_type":"code","source":["send_example_telemetry(\"text_classification_notebook\", framework=\"pytorch\")"],"metadata":{"id":"7HBKjDjP2OlR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"xx75ZPy5-dL1"}},{"cell_type":"markdown","source":["### Model Definition\n","Pick a model from the [Model Hub](https://huggingface.co/models) with a  clasffification head \n","\n","Adjust the batch size as needed to not run out of memory\n","\n","why choose distilbert-base-uncased with the task of sst2?\n","- sst2/sentiment analysis, can help identify the hate speech\n","- distilbert-base-uncased: 110m Params compared other bert-large-uncased which is  3x more (340M)"],"metadata":{"id":"GO2lfsx-MY-n"}},{"cell_type":"code","source":["task = \"hate_speech_detection\"\n","model_checkpoint = \"distilbert-base-uncased\"\n","batch_size = 16\n","\n","# from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","\n","# tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","# model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n","\n","# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n","# with torch.no_grad():\n","#     logits = model(**inputs).logits\n","\n","# predicted_class_id = logits.argmax().item()\n","# model.config.id2label[predicted_class_id]"],"metadata":{"id":"fJ5TKp8IMX-i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading the existing model's dataset\n","\n","Picking a dataset:\n","- [SST-2](https://nlp.stanford.edu/sentiment/index.html) (Stanford Sentiment Treebank) Determine if the sentence has a positive or negative sentiment."],"metadata":{"id":"wcYxsUZa3kD_"}},{"cell_type":"code","source":["existing_tasks = [\"cola\", \"mnli\", \"mnli-mm\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]\n","\n","actual_task = \"sst2\"\n","data = load_dataset(\"glue\", actual_task)\n","metric = load_metric('glue', actual_task)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["210483cad01847e58be29f530e5ee8cb","4e56946c90214f27a89a16113cea861d","5417a60f28be450a8cc7938dfa12e0a2","46e7cba5323643189a971b32fd0bb809","a9adb03db8d04ce9852e852d40cd841f","dd8ddd6f20114f3d8b09b872d27cbc60","b4831d3b79f449d89495fc7f11f4df93","9bc1ba4b9d2345a98a594a4b05dbc293","ba6675b2cea34a0c8cb08a39f2844d40","32d5648aa6e44e0e96929fc91fc999d5","7ba70446b54341ccb46d9cb5cc3f4105"]},"id":"idoucMRc3V7r","executionInfo":{"status":"ok","timestamp":1679669724328,"user_tz":-480,"elapsed":2909,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"03efe795-e7ba-4148-c322-c2aaa7d92cca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"210483cad01847e58be29f530e5ee8cb"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["<ipython-input-11-f395401d8273>:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric('glue', actual_task)\n"]}]},{"cell_type":"code","source":["# metric[\"accuracy\"]"],"metadata":{"id":"3XedHI5xshhh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checking the dictionary format of the data\n","display(data)\n","\n","#checking what the first entry in train\n","data[\"train\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"hAKuOITC71cN","executionInfo":{"status":"ok","timestamp":1679669724329,"user_tz":-480,"elapsed":12,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"83e23c0d-ce32-4b5e-b2cd-f05ad5e282d6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 67349\n","    })\n","    validation: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 872\n","    })\n","    test: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 1821\n","    })\n","})"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'sentence': 'hide new secretions from the parental units ',\n"," 'label': 0,\n"," 'idx': 0}"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["Pick random entries to get a sense of what the data looks like\n","1. turn the into dataset object into a dataframae so you can get samples from it "],"metadata":{"id":"4LgQted68YV-"}},{"cell_type":"code","source":["pd.DataFrame(data[\"train\"]).sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"-XYz3Rap8Yl1","executionInfo":{"status":"ok","timestamp":1679669735300,"user_tz":-480,"elapsed":9117,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"65d2d6ab-c4e9-4bd0-e9d6-0a22767ce02b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                sentence  label    idx\n","57574  award-winning english cinematographer giles nu...      1  57574\n","60141  it 'll probably be in video stores by christma...      0  60141\n","9065                     sensuality and a conniving wit       1   9065\n","42544                                much self-centered       0  42544\n","38159                                      your disgust       0  38159\n","37579      a story already overladen with plot conceits       0  37579\n","36247  too many films that can be as simultaneously f...      1  36247\n","60842  takes a fresh and absorbing look at a figure w...      1  60842\n","28010                                 love , family and       1  28010\n","45759  in all fairness , i must report that the child...      1  45759"],"text/html":["\n","  <div id=\"df-f96e51db-f477-4085-96c5-2c112fc35ff5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","      <th>idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>57574</th>\n","      <td>award-winning english cinematographer giles nu...</td>\n","      <td>1</td>\n","      <td>57574</td>\n","    </tr>\n","    <tr>\n","      <th>60141</th>\n","      <td>it 'll probably be in video stores by christma...</td>\n","      <td>0</td>\n","      <td>60141</td>\n","    </tr>\n","    <tr>\n","      <th>9065</th>\n","      <td>sensuality and a conniving wit</td>\n","      <td>1</td>\n","      <td>9065</td>\n","    </tr>\n","    <tr>\n","      <th>42544</th>\n","      <td>much self-centered</td>\n","      <td>0</td>\n","      <td>42544</td>\n","    </tr>\n","    <tr>\n","      <th>38159</th>\n","      <td>your disgust</td>\n","      <td>0</td>\n","      <td>38159</td>\n","    </tr>\n","    <tr>\n","      <th>37579</th>\n","      <td>a story already overladen with plot conceits</td>\n","      <td>0</td>\n","      <td>37579</td>\n","    </tr>\n","    <tr>\n","      <th>36247</th>\n","      <td>too many films that can be as simultaneously f...</td>\n","      <td>1</td>\n","      <td>36247</td>\n","    </tr>\n","    <tr>\n","      <th>60842</th>\n","      <td>takes a fresh and absorbing look at a figure w...</td>\n","      <td>1</td>\n","      <td>60842</td>\n","    </tr>\n","    <tr>\n","      <th>28010</th>\n","      <td>love , family and</td>\n","      <td>1</td>\n","      <td>28010</td>\n","    </tr>\n","    <tr>\n","      <th>45759</th>\n","      <td>in all fairness , i must report that the child...</td>\n","      <td>1</td>\n","      <td>45759</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f96e51db-f477-4085-96c5-2c112fc35ff5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f96e51db-f477-4085-96c5-2c112fc35ff5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f96e51db-f477-4085-96c5-2c112fc35ff5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["### Loading the data for hate speech\n","\n","data description (based on github):\n","- hate_speech = number of CF users who judged the tweet to be hate speech.\n","\n","- offensive_language = number of CF users who judged the tweet to be offensive.\n","\n","- neither = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n","\n","- class = class label for majority of CF users. \n","  - 0 - hate speech \n","  - 1 - offensive language \n","  - 2 - neither\n"],"metadata":{"id":"9TWkX00_H-e5"}},{"cell_type":"code","source":["#\n","dataset_name = \"hate_speech_offensive\"\n","\n","hate_speech_ds  = load_dataset(dataset_name)\n","# hate_speech = pd.read_csv(\"hate_speech_labeled_data.csv\")"],"metadata":{"id":"-OXEHQPe3yG2","executionInfo":{"status":"ok","timestamp":1679669736902,"user_tz":-480,"elapsed":1607,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["4983fb7c2cca461fb5539e73cccd6ac7","ec953004e4534ac68da1efba05da22b2","fe72c604335b42d895dd3ce73348a057","86149739912d4bf7a46949063be7b2bc","10f1b68b08f141a8bcbd55adab4e7821","a2925e1f42b04317a660d91d4f622fce","b984373baa084d959c74f810100f3a67","9149d8e855694b8294debd55b71a53d1","16ed605b5cb441758581fe9c80ffac1d","7dae63d1f4fb4c8c89725b2d7a8d5f51","a222ab21d8c04314918778412ac91e77"]},"outputId":"4da73031-3346-49dd-f7e4-1fc24411bae4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset hate_speech_offensive (/root/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4983fb7c2cca461fb5539e73cccd6ac7"}},"metadata":{}}]},{"cell_type":"code","source":["hate_speech_df = pd.DataFrame(hate_speech_ds[\"train\"])"],"metadata":{"id":"C2ju11DEp7Nw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hate_speech_df"],"metadata":{"id":"KkitdRToqdd0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Showing some samples of each class"],"metadata":{"id":"0hyfR7plZ4h0"}},{"cell_type":"code","source":["#adding to expand the tweet to see the full text\n","pd.set_option('display.max_colwidth', None)\n","pd.set_option('display.max_colwidth', -1)\n","\n","print(\"Hate speech\")\n","display(hate_speech_df[hate_speech_df[\"class\"]==0].sample(10)[[\"class\",\"tweet\"]])\n","print(\"-----------------------------------------------------------------\")\n","\n","print(\"Offensive language\")\n","display(hate_speech_df[hate_speech_df[\"class\"]==1].sample(10)[[\"class\",\"tweet\"]])\n","print(\"-----------------------------------------------------------------\")\n","\n","print(\"Neither\")\n","print()\n","display(hate_speech_df[hate_speech_df[\"class\"]==2].sample(10)[[\"class\",\"tweet\"]])\n","print(\"-----------------------------------------------------------------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Sjt7GXArZ6NP","executionInfo":{"status":"ok","timestamp":1679669740911,"user_tz":-480,"elapsed":15,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"302f033b-c581-4ee4-f263-09cabae60f9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hate speech\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-73231f90a4b2>:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n","  pd.set_option('display.max_colwidth', -1)\n"]},{"output_type":"display_data","data":{"text/plain":["       class  \\\n","21168  0       \n","3408   0       \n","22483  0       \n","3591   0       \n","12189  0       \n","19303  0       \n","17812  0       \n","15420  0       \n","5939   0       \n","10929  0       \n","\n","                                                                                                                                                    tweet  \n","21168  Stoni is a fuckin queer...                                                                                                                          \n","3408   @HuffingtonPost im American, don't give 2 shits about the beaners, ship them beaners back                                                           \n","22483  Wassup wit all these fucc niccas                                                                                                                    \n","3591   @JacobbBacker fag                                                                                                                                   \n","12189  Kanye west is a faggot                                                                                                                              \n","19303  RT @ivanrabago_: @staycoolwheels @Studhardt22 Joshua is a faggot. Just suspend him on those grounds                                                 \n","17812  RT @TopBlokeBill: Are you Justin Beiber? Because your a Fucken gay cunt @Arii_nV http://t.co/pgHISyDEyB                                             \n","15420  RT @HG_Shit: Mfs still in the same spot as 3yrs ago. Beefing with the same nighas. Sleeping with the same hoes. Eating from the same restau&#8230;  \n","5939   @erinscafe We hate the Yankees though, right? I feel like I'm really good at hating them.                                                           \n","10929  I swear these anon fags go to protests just to take pictures to post to Twitter. \"Look, I was there...Like me\"                                      "],"text/html":["\n","  <div id=\"df-8c506923-11d2-4afd-9940-869bc8f8a27c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>21168</th>\n","      <td>0</td>\n","      <td>Stoni is a fuckin queer...</td>\n","    </tr>\n","    <tr>\n","      <th>3408</th>\n","      <td>0</td>\n","      <td>@HuffingtonPost im American, don't give 2 shits about the beaners, ship them beaners back</td>\n","    </tr>\n","    <tr>\n","      <th>22483</th>\n","      <td>0</td>\n","      <td>Wassup wit all these fucc niccas</td>\n","    </tr>\n","    <tr>\n","      <th>3591</th>\n","      <td>0</td>\n","      <td>@JacobbBacker fag</td>\n","    </tr>\n","    <tr>\n","      <th>12189</th>\n","      <td>0</td>\n","      <td>Kanye west is a faggot</td>\n","    </tr>\n","    <tr>\n","      <th>19303</th>\n","      <td>0</td>\n","      <td>RT @ivanrabago_: @staycoolwheels @Studhardt22 Joshua is a faggot. Just suspend him on those grounds</td>\n","    </tr>\n","    <tr>\n","      <th>17812</th>\n","      <td>0</td>\n","      <td>RT @TopBlokeBill: Are you Justin Beiber? Because your a Fucken gay cunt @Arii_nV http://t.co/pgHISyDEyB</td>\n","    </tr>\n","    <tr>\n","      <th>15420</th>\n","      <td>0</td>\n","      <td>RT @HG_Shit: Mfs still in the same spot as 3yrs ago. Beefing with the same nighas. Sleeping with the same hoes. Eating from the same restau&amp;#8230;</td>\n","    </tr>\n","    <tr>\n","      <th>5939</th>\n","      <td>0</td>\n","      <td>@erinscafe We hate the Yankees though, right? I feel like I'm really good at hating them.</td>\n","    </tr>\n","    <tr>\n","      <th>10929</th>\n","      <td>0</td>\n","      <td>I swear these anon fags go to protests just to take pictures to post to Twitter. \"Look, I was there...Like me\"</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c506923-11d2-4afd-9940-869bc8f8a27c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8c506923-11d2-4afd-9940-869bc8f8a27c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8c506923-11d2-4afd-9940-869bc8f8a27c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["-----------------------------------------------------------------\n","Offensive language\n"]},{"output_type":"display_data","data":{"text/plain":["       class  \\\n","14321  1       \n","11685  1       \n","17411  1       \n","159    1       \n","15266  1       \n","20142  1       \n","2364   1       \n","23579  1       \n","9214   1       \n","22829  1       \n","\n","                                                                                                                                                                tweet  \n","14321  RT @BasedZae: When lil b said &#8220;Word around town that I aint got no bitches? what?! Thats a damn lie nigga my nuts is my witness&#8221; http://t.c&#8230;  \n","11685  If you're being a little scared bitch about the POSSIBILITY of a louisville purge...just go to Ferguson.                                                        \n","17411  RT @SteadmanTerri: @wheeler_kashhh Mann fuckk dat shit!!..fuckk dat bitch!! &#128514;&#128514;                                                                  \n","159    \"@KingCuh: @16stanleys io io alu record ho vine sai pe hahahaha\" lol anywaaaaaays..... haha                                                                     \n","15266  RT @FuckTraVonn: @TropicalKyle I saw the xxx but I just thought she was a hoe                                                                                   \n","20142  RT @thebootycluh_: &#8220;@_xoxoMOOKY: Why do niggas settle for easy bitches ? Like don't y'all wanna bitch that challenges you to better yoursel&#8230;        \n","2364   @AbstractLife man too much damn giggling was going. He was offering $40 tips and shit. Lol think I even heard the bitch spit a couple times                     \n","23579  animal crackers are the fuckin bomb, yo                                                                                                                         \n","9214   Fuc u say ? &#8220;@AyyyeThatsChubb: All these hoes look good on IG&#8221; http://t.co/PlsFL84cDp                                                               \n","22829  Who's ready for nigger spam?                                                                                                                                    "],"text/html":["\n","  <div id=\"df-81c7ac18-f7d5-4055-bedb-e4f7966299f6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>14321</th>\n","      <td>1</td>\n","      <td>RT @BasedZae: When lil b said &amp;#8220;Word around town that I aint got no bitches? what?! Thats a damn lie nigga my nuts is my witness&amp;#8221; http://t.c&amp;#8230;</td>\n","    </tr>\n","    <tr>\n","      <th>11685</th>\n","      <td>1</td>\n","      <td>If you're being a little scared bitch about the POSSIBILITY of a louisville purge...just go to Ferguson.</td>\n","    </tr>\n","    <tr>\n","      <th>17411</th>\n","      <td>1</td>\n","      <td>RT @SteadmanTerri: @wheeler_kashhh Mann fuckk dat shit!!..fuckk dat bitch!! &amp;#128514;&amp;#128514;</td>\n","    </tr>\n","    <tr>\n","      <th>159</th>\n","      <td>1</td>\n","      <td>\"@KingCuh: @16stanleys io io alu record ho vine sai pe hahahaha\" lol anywaaaaaays..... haha</td>\n","    </tr>\n","    <tr>\n","      <th>15266</th>\n","      <td>1</td>\n","      <td>RT @FuckTraVonn: @TropicalKyle I saw the xxx but I just thought she was a hoe</td>\n","    </tr>\n","    <tr>\n","      <th>20142</th>\n","      <td>1</td>\n","      <td>RT @thebootycluh_: &amp;#8220;@_xoxoMOOKY: Why do niggas settle for easy bitches ? Like don't y'all wanna bitch that challenges you to better yoursel&amp;#8230;</td>\n","    </tr>\n","    <tr>\n","      <th>2364</th>\n","      <td>1</td>\n","      <td>@AbstractLife man too much damn giggling was going. He was offering $40 tips and shit. Lol think I even heard the bitch spit a couple times</td>\n","    </tr>\n","    <tr>\n","      <th>23579</th>\n","      <td>1</td>\n","      <td>animal crackers are the fuckin bomb, yo</td>\n","    </tr>\n","    <tr>\n","      <th>9214</th>\n","      <td>1</td>\n","      <td>Fuc u say ? &amp;#8220;@AyyyeThatsChubb: All these hoes look good on IG&amp;#8221; http://t.co/PlsFL84cDp</td>\n","    </tr>\n","    <tr>\n","      <th>22829</th>\n","      <td>1</td>\n","      <td>Who's ready for nigger spam?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81c7ac18-f7d5-4055-bedb-e4f7966299f6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-81c7ac18-f7d5-4055-bedb-e4f7966299f6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-81c7ac18-f7d5-4055-bedb-e4f7966299f6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["-----------------------------------------------------------------\n","Neither\n","\n"]},{"output_type":"display_data","data":{"text/plain":["       class  \\\n","13811  2       \n","5503   2       \n","20846  2       \n","17404  2       \n","7226   2       \n","13659  2       \n","6594   2       \n","11264  2       \n","902    2       \n","16422  2       \n","\n","                                                                                                                                                        tweet  \n","13811  Permanent slit in my eyebrow from when I tumbled down the bleachers when I was little.... I stayed in the ER                                            \n","5503   @allsportsbruh how? All of the QBs we had before this season were trash. They brought in a veteran so they could have someone to play                   \n","20846  Sighs of relief from Beijing Guoan fans &amp; #China's govt as club nips Japanese rival 2-1 in tense match: #football http://t.co/EesEOR7Iba            \n","17404  RT @SportsNation: So, Yanks have signed Brian McCann &amp; Jacoby Ellsbury. Rumor has it, they still want Robinson Cano, Babe Ruth, Miguel Cabr&#8230;  \n","7226   @tyler_wilde CH3BURASHKA sure gets to be a nit-picky Russian monkey/bear thing sometimes, doesn't he?                                                   \n","13659  Only Americans are degenerate enough to 'honor' their war dead by having a barbecue. Anyone who 'grills out' for Memorial Day is trash.                 \n","6594   @longbongchris mk Hun just textith me                                                                                                                   \n","11264  I'm finna see the Yankees win a baseball game                                                                                                           \n","902    #porn,#android,#iphone,#ipad,#sex,#xxx, | #Teen | Cutie lesbian teens toy slits http://t.co/ZS05enjjwm                                                  \n","16422  RT @MelissaTweets: Scott Walker investigate. Christie's Bridgegate. Perry's drunk monkey Dem DA-gate. All men innocent. All threats to left&#8230;      "],"text/html":["\n","  <div id=\"df-bc9c06d9-8128-4984-b729-b73e71521607\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>13811</th>\n","      <td>2</td>\n","      <td>Permanent slit in my eyebrow from when I tumbled down the bleachers when I was little.... I stayed in the ER</td>\n","    </tr>\n","    <tr>\n","      <th>5503</th>\n","      <td>2</td>\n","      <td>@allsportsbruh how? All of the QBs we had before this season were trash. They brought in a veteran so they could have someone to play</td>\n","    </tr>\n","    <tr>\n","      <th>20846</th>\n","      <td>2</td>\n","      <td>Sighs of relief from Beijing Guoan fans &amp;amp; #China's govt as club nips Japanese rival 2-1 in tense match: #football http://t.co/EesEOR7Iba</td>\n","    </tr>\n","    <tr>\n","      <th>17404</th>\n","      <td>2</td>\n","      <td>RT @SportsNation: So, Yanks have signed Brian McCann &amp;amp; Jacoby Ellsbury. Rumor has it, they still want Robinson Cano, Babe Ruth, Miguel Cabr&amp;#8230;</td>\n","    </tr>\n","    <tr>\n","      <th>7226</th>\n","      <td>2</td>\n","      <td>@tyler_wilde CH3BURASHKA sure gets to be a nit-picky Russian monkey/bear thing sometimes, doesn't he?</td>\n","    </tr>\n","    <tr>\n","      <th>13659</th>\n","      <td>2</td>\n","      <td>Only Americans are degenerate enough to 'honor' their war dead by having a barbecue. Anyone who 'grills out' for Memorial Day is trash.</td>\n","    </tr>\n","    <tr>\n","      <th>6594</th>\n","      <td>2</td>\n","      <td>@longbongchris mk Hun just textith me</td>\n","    </tr>\n","    <tr>\n","      <th>11264</th>\n","      <td>2</td>\n","      <td>I'm finna see the Yankees win a baseball game</td>\n","    </tr>\n","    <tr>\n","      <th>902</th>\n","      <td>2</td>\n","      <td>#porn,#android,#iphone,#ipad,#sex,#xxx, | #Teen | Cutie lesbian teens toy slits http://t.co/ZS05enjjwm</td>\n","    </tr>\n","    <tr>\n","      <th>16422</th>\n","      <td>2</td>\n","      <td>RT @MelissaTweets: Scott Walker investigate. Christie's Bridgegate. Perry's drunk monkey Dem DA-gate. All men innocent. All threats to left&amp;#8230;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc9c06d9-8128-4984-b729-b73e71521607')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bc9c06d9-8128-4984-b729-b73e71521607 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bc9c06d9-8128-4984-b729-b73e71521607');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["-----------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["Dataset observations:\n","1. Majority (77%) of the examples are  offensive language \n","2. We rarely find hate speech having only 1430 examples (5% of the whole dataset)\n","\n","Possible experiments:\n","- Rebalance the dataset via:\n","  - oversampling \n","  - undersampling \n"],"metadata":{"id":"T8LOMx13Ih3J"}},{"cell_type":"code","source":[],"metadata":{"id":"WklD5NVZZgT4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#check the distribution of the classes\n","hate_speech_df[\"class\"].value_counts(normalize=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sSKQqmbFHX5S","executionInfo":{"status":"ok","timestamp":1679669740911,"user_tz":-480,"elapsed":12,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"4303870e-35d0-4b4d-f526-fa05ddbf3ad0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    0.774321\n","2    0.167978\n","0    0.057701\n","Name: class, dtype: float64"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["check for nulls and drop them"],"metadata":{"id":"Ogc7l71EZvaV"}},{"cell_type":"code","source":["hate_speech_df.isna().sum()\n","hate_speech_df = hate_speech_df.dropna()\n"],"metadata":{"id":"kYi5zFSdZxCv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","## Preprocessing"],"metadata":{"id":"JYlmfg7Kj_yz"}},{"cell_type":"markdown","source":["### Tokenize\n","\n","1. Defining the tokenizer (tokenizer is a method or process to convert the words into numbers such that the computer can understand it)\n","\n","2. sample of the tokenizer\n","\n","\n"],"metadata":{"id":"9JXwR7Li3qkt"}},{"cell_type":"code","source":["#create a toeknizer that fits the model in this case bert-distil-uncase\n","#use the vocab of the pretrained model\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n","\n","#input is the id in of the vocabulary \n","tokenizer(\"it's me, hi, I'm the problem, it's me\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"unsIv2ga3i4s","executionInfo":{"status":"ok","timestamp":1679669740912,"user_tz":-480,"elapsed":10,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"45ac2c9c-eff5-4f83-e25d-fa6a24c8464c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [101, 2009, 1005, 1055, 2033, 1010, 7632, 1010, 1045, 1005, 1049, 1996, 3291, 1010, 2009, 1005, 1055, 2033, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["tokenize curse words or profanity to check what's the result"],"metadata":{"id":"3nwFsc1i4Dzf"}},{"cell_type":"code","source":["print(tokenizer(\"faggot\"))\n","print(tokenizer(\"bitch\"))\n","print(tokenizer(\"bitch\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zmzrd75e4I0N","executionInfo":{"status":"ok","timestamp":1679670111075,"user_tz":-480,"elapsed":6,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"4271933f-f62f-4b62-f1d6-cdbd60ab74b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [101, 6904, 13871, 4140, 102], 'attention_mask': [1, 1, 1, 1, 1]}\n","{'input_ids': [101, 7743, 102], 'attention_mask': [1, 1, 1]}\n","{'input_ids': [101, 7743, 102], 'attention_mask': [1, 1, 1]}\n"]}]},{"cell_type":"markdown","source":["\n","<!-- After tokenzing,use pytorch to train the model to take advantage of colab free gpu:\n","\n","- video source: https://youtu.be/Dh9CL8fyG80\n","- link source: https://youtu.be/Dh9CL8fyG80 -->\n"],"metadata":{"id":"a2CvvZe-7OxL"}},{"cell_type":"code","source":["\n","# sentence1_key, sentence2_key = task_to_keys[task]\n","sentence1_key = \"sentence\"\n","\n","#print the sentence\n","print(f\"Sentence: {data['train'][0][sentence1_key]}\")\n","\n","#print the tokenized sentence \n","tokenizer(data['train'][0][sentence1_key],truncation=True) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CbIipGEz7N-z","executionInfo":{"status":"ok","timestamp":1679670111076,"user_tz":-480,"elapsed":5,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"a3f4c78c-14fe-480e-ed30-8a69ff1db297"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence: hide new secretions from the parental units \n"]},{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["Change the sample code since we're using ```sst2``` only, which means we only need sentence column. I'm using a different dataset so the ```sentence_key``` is tweet\n","\n","The argument:\n","- `truncation=True`: This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model.\n","\n","Why did I tokenize first?\n","-  because its better to tokenize first then oversample and undersample, and also need to train test plit\n","- so don't need to retokenizing the same tweets"],"metadata":{"id":"rHgX_OBkWI9D"}},{"cell_type":"code","source":["#pre process function for existing data from dataset library\n","def preprocess_function(examples):\n","  return tokenizer(examples[\"tweet\"], truncation=True)\n","\n","# #preprocessing on hate_speech dataset\n","# def my_preprocess_function(examples):\n","#   return tokenizer(examples, truncation=True)\n","\n","#encoded hate_speech for fine tuning\n","# endocded_hspeech = hate_speech[\"tweet\"].map(my_preprocess_function)\n","\n","encoded_ds = hate_speech_ds.map(preprocess_function)\n","\n","#check what encoded ds looks like\n","encoded_ds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPT_obn3VBmK","executionInfo":{"status":"ok","timestamp":1679670111608,"user_tz":-480,"elapsed":3,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"dda8cf60-9826-4537-cf25-8c774e849e44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5/cache-85452f951e484c6b.arrow\n"]},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['count', 'hate_speech_count', 'offensive_language_count', 'neither_count', 'class', 'tweet', 'input_ids', 'attention_mask'],\n","        num_rows: 24783\n","    })\n","})"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["hate_speech_df = pd.DataFrame(encoded_ds[\"train\"])"],"metadata":{"id":"32aRlTWga_LS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hate_speech_df"],"metadata":{"id":"zyx-9J8R3cP-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Undersampling and Oversampling\n","\n","1. Defining the tokenizer (tokenizer is a method or process to convert the words into numbers such that the computer can understand it)\n","2. sample of the tokenizer\n"],"metadata":{"id":"fosphpGTd_Bv"}},{"cell_type":"markdown","source":["\n","\n","Perform oversampling using [Imbalanced-Learn Library](https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/)\n","\n","-  ```minority``` parameter means,  majority of 1,000 examples and the minority class had 100, this strategy would oversampling the minority class so that it has 1,000 examples.\n","\n","- Need to oversample twice becuase we have 3 classes, after the first over sampling only 0.0 has increased  from 2050 to 30333 (same logic applies to oversampling)\n","\n"],"metadata":{"id":"CFXa1VPMZTJl"}},{"cell_type":"code","source":["# eval\n","X = hate_speech_df[[\"tweet\",'input_ids', 'attention_mask']].values\n","y = hate_speech_df[\"class\"].values\n","\n","print(\"distrubution before over sampling\")\n","print(Counter(y))\n","#d 1,000 examples and the minority class had 100, this strategy would oversampling the minority class so that it has 1,000 examples.\n","oversample = RandomOverSampler(random_state=0,sampling_strategy='minority')\n","\n","X_over, y_over = oversample.fit_resample(X, y)\n","print(\"distrubution after over sampling\")\n","print(Counter(y_over))\n","\n","# need to oversample twice becuase we have 3 classes\n","# after the first over sampling only 0.0 has increased  from 2050 to 30333\n","X_over, y_over = oversample.fit_resample(X_over, y_over)\n","print(\"distrubution after 2nd over sampling\")\n","print(Counter(y_over))\n","\n","\n","over_h_speech = pd.DataFrame(X_over, columns=[\"tweet\",'input_ids', 'attention_mask'])\n","over_h_speech[\"label\"] = y_over"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HsPDp6_E-Vyb","executionInfo":{"status":"ok","timestamp":1679670115064,"user_tz":-480,"elapsed":7,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"f02c99c3-cea4-40f2-a7a5-deacd50115e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["distrubution before over sampling\n","Counter({1: 19190, 2: 4163, 0: 1430})\n","distrubution after over sampling\n","Counter({1: 19190, 0: 19190, 2: 4163})\n","distrubution after 2nd over sampling\n","Counter({2: 19190, 1: 19190, 0: 19190})\n"]}]},{"cell_type":"code","source":["# over_h_speech"],"metadata":{"id":"k1aVQ16jgT8w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Perform undersampling using [Imbalanced-Learn Library](https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/)\n"],"metadata":{"id":"O9ktoI98cGHG"}},{"cell_type":"code","source":["undersample = RandomUnderSampler(random_state=0,sampling_strategy='majority')\n","\n","X_under, y_under = undersample.fit_resample(X, y)\n","print(\"distrubution after under sampling\")\n","print(Counter(y_under))\n","\n","X_under, y_under = undersample.fit_resample(X_under, y_under)\n","print(\"distrubution after 2nd under sampling\")\n","print(Counter(y_under))\n","\n","# under_h_speech = pd.DataFrame({\"tweet\":X_under.flatten(),\"class\":y_under})\n","\n","\n","under_h_speech = pd.DataFrame(X_over, columns=[\"tweet\",'input_ids', 'attention_mask'])\n","under_h_speech[\"label\"] = y_over\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rqwboZBucKUx","executionInfo":{"status":"ok","timestamp":1679670115064,"user_tz":-480,"elapsed":6,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"1f67353e-1baf-48d1-a86f-d4d09224e500"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["distrubution after under sampling\n","Counter({2: 4163, 0: 1430, 1: 1430})\n","distrubution after 2nd under sampling\n","Counter({0: 1430, 1: 1430, 2: 1430})\n"]}]},{"cell_type":"markdown","source":["### Train test split on the following:\n","- hate_speech\n","- over_h_speech\n","- under_h_speech"],"metadata":{"id":"MRmk9hehjw25"}},{"cell_type":"code","source":["hate_speech_df.columns = ['count', 'hate_speech_count', 'offensive_language_count',\n","       'neither_count', 'label', 'tweet', 'input_ids', 'attention_mask']"],"metadata":{"id":"-CZFcLDIN8tu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","train, test = train_test_split(hate_speech_df, test_size=0.2)\n","over_train, over_test = train_test_split(over_h_speech, test_size=0.2)\n","under_train, under_test = train_test_split(under_h_speech, test_size=0.2)\n","\n","\n","                               "],"metadata":{"id":"M-OPvr8bj-O5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create a Dataset Dictionary\n","- So we can use it for the model\n","\n","reference: The `dataset` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set (with more keys for the mismatched validation and test set in the special case of `mnli`)."],"metadata":{"id":"CCzb6ac0lujE"}},{"cell_type":"code","source":["# Dataset.from_pandas(over_train)\n","\n","\n","\n","train_ds = Dataset.from_pandas(train, split=\"train\")\n","test_ds = Dataset.from_pandas(test, split=\"test\")\n","\n","o_train_ds = Dataset.from_pandas(over_train, split=\"o_train\")\n","o_test_ds = Dataset.from_pandas(over_train, split=\"o_test\")\n","\n","\n","u_train_ds = Dataset.from_pandas(under_train, split=\"u_train\")\n","u_test_ds = Dataset.from_pandas(under_test, split=\"u_test\")\n","\n"],"metadata":{"id":"jPAk-E84l-9p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vek29OOTvXIK","executionInfo":{"status":"ok","timestamp":1679670121847,"user_tz":-480,"elapsed":5,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"dfd8389d-55ea-4ccd-f485-edbcfcff2afe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['count', 'hate_speech_count', 'offensive_language_count', 'neither_count', 'label', 'tweet', 'input_ids', 'attention_mask', '__index_level_0__'],\n","    num_rows: 19826\n","})"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["\n","#processed dataset\n","dataset_proc = DatasetDict({\"train\":train_ds,\n","                             \"test\":test_ds, \n","                             \"o_train_ds\":o_train_ds,\n","                             \"o_test_ds\":o_test_ds,\n","                             \"u_train_ds\":u_train_ds,\n","                             \"u_test_ds\":u_test_ds, })\n"],"metadata":{"id":"LppdmODameD0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dataset_proc"],"metadata":{"id":"OeV5eLL3wbb1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fine-tuning the model\n","\n","1. load the model into cache\n","2. .tocuda() to use gpu [source](https://huggingface.co/docs/transformers/perf_train_gpu_one)\n","\n"],"metadata":{"id":"n0cHtpXn3tHL"}},{"cell_type":"code","source":["\n","labels = 3\n","# model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=labels)\n","##comment this out if you just want cpu\n","model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=labels).to(\"cuda\")"],"metadata":{"id":"VPSCNjlG3i97","colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["c7a7c5b5d3954a9a88afa445a764775e","be445e67b10a4a3a9a0ceb0cf30b992c","7731aa1959d54966baf4406c1a8ba863","aaaa912e8aa54fca8ab1ba751364d44d","52eca921fef44509859239976ff5ee14","94b183957bc34dc588cd1af085ec3122","56081959adc640dcb950f256e7609e2d","fdfac8d378cf4b798fa96f86e774352e","df322d52719d488f876cf17980127ac6","b14176a574de4bae9562599ca1498ae8","5ed7c4e1f7304e26b074831a63c7b7e7"]},"executionInfo":{"status":"ok","timestamp":1679662341347,"user_tz":-480,"elapsed":11286,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"dd7f9ef4-8b95-423d-dad9-2ada338cc95a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7a7c5b5d3954a9a88afa445a764775e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["defining training arguments\n","\n","required attributes\n","-  folder name for model checkpoint storage\n","\n","- evaluation_strategy (str or IntervalStrategy, optional, defaults to \"no\") — The evaluation strategy to adopt during training. Possible values are:\n","- per_device_train_batch_size (int, optional, defaults to 8) — The batch size per GPU/TPU core/CPU for training.\n","- we can push the model to the Hub regularly during training. Remove it if you didn't follow the installation steps at the top of the notebook"],"metadata":{"id":"bCs_PJ7MxSOd"}},{"cell_type":"code","source":[],"metadata":{"id":"ESW7nnEKM3wy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_name = model_checkpoint.split(\"/\")[-1]\n","batch_size= 8\n","metric_name = \"accuracy\"\n","task = \"hate_speech\"\n","\n","args = TrainingArguments(\n","    f\"{model_name}-finetuned-{task}\",\n","    evaluation_strategy = \"epoch\",\n","    save_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=metric_name,\n","    push_to_hub=True,\n",")"],"metadata":{"id":"vToFIEmC3i_8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["measurement of performance/ prediction \n","1. `metric` we loaded earlier\n","2. the prediction is rgmax of our predicted logits or predictions[:, 0]\n"],"metadata":{"id":"wdAwHN_DypxV"}},{"cell_type":"code","source":["def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = predictions[:, 0]\n","    return metric.compute(predictions=predictions, references=labels)"],"metadata":{"id":"MV__LMZl3vcq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pb0hgcuuGO7p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define the validation key of sst2\n","validation_key  = \"validation\"\n","trainer = Trainer(model,\n","                  args,\n","                  train_dataset=dataset_proc[\"train\"],\n","                  eval_dataset=dataset_proc[\"test\"],\n","                  tokenizer=tokenizer,\n","                  compute_metrics=compute_metrics)\n","\n"],"metadata":{"id":"pmC-tbgk3jCA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679662705636,"user_tz":-480,"elapsed":4058,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"e7080325-b1eb-4f7c-dafb-17fc05a52850"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/distilbert-base-uncased-finetuned-hate_speech is already a clone of https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech. Make sure you pull the latest changes with `repo.git_pull()`.\n","WARNING:huggingface_hub.repository:/content/distilbert-base-uncased-finetuned-hate_speech is already a clone of https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech. Make sure you pull the latest changes with `repo.git_pull()`.\n"]}]},{"cell_type":"code","source":["result = trainer.train()\n","print_summary(result)\n","#why is the training and loss and accuracy all the same?\n","\n","# print_summary(result)"],"metadata":{"id":"hPL51L_s3yAT","colab":{"base_uri":"https://localhost:8080/","height":284},"executionInfo":{"status":"ok","timestamp":1679664859694,"user_tz":-480,"elapsed":784327,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"8a2f1e0c-06ff-4420-e9d3-b49c96b2e0e9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='6200' max='6200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6200/6200 13:03, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.190000</td>\n","      <td>0.294211</td>\n","      <td>0.056082</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.193000</td>\n","      <td>0.294211</td>\n","      <td>0.056082</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.188300</td>\n","      <td>0.294211</td>\n","      <td>0.056082</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.183500</td>\n","      <td>0.294211</td>\n","      <td>0.056082</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.192500</td>\n","      <td>0.294211</td>\n","      <td>0.056082</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Time: 784.05\n","Samples/second: 126.43\n","GPU memory occupied: 9937 MB.\n"]}]},{"cell_type":"code","source":["# result"],"metadata":{"id":"QKF7P4vJA6_b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"id":"WJFeNDFM3yEY","executionInfo":{"status":"ok","timestamp":1679664868652,"user_tz":-480,"elapsed":8963,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"colab":{"base_uri":"https://localhost:8080/","height":141},"outputId":"02007a15-cbd0-46a9-e32a-5ee150045852"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='310' max='310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [310/310 00:09]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.29421094059944153,\n"," 'eval_accuracy': 0.0560823078474884,\n"," 'eval_runtime': 9.5234,\n"," 'eval_samples_per_second': 520.508,\n"," 'eval_steps_per_second': 32.551,\n"," 'epoch': 5.0}"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["trainer.push_to_hub()"],"metadata":{"id":"CSQDumKQTdwx","executionInfo":{"status":"ok","timestamp":1679664883973,"user_tz":-480,"elapsed":15323,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"colab":{"base_uri":"https://localhost:8080/","height":282},"outputId":"393ee0b0-e8af-492f-9876-e76312eb9e62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["To https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech\n","   5dc7512..8b3f0f8  main -> main\n","\n","WARNING:huggingface_hub.repository:To https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech\n","   5dc7512..8b3f0f8  main -> main\n","\n","To https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech\n","   8b3f0f8..bd3a48b  main -> main\n","\n","WARNING:huggingface_hub.repository:To https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech\n","   8b3f0f8..bd3a48b  main -> main\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["'https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech/commit/8b3f0f829c7a6acf7c198dea9b0ba000532167ca'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["f\"{model_name}-finetuned-{task}\""],"metadata":{"id":"YdCQESK3Tdzg","executionInfo":{"status":"ok","timestamp":1679664883973,"user_tz":-480,"elapsed":5,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"a69be3c2-4d52-4847-9d8e-87968e978b8d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'distilbert-base-uncased-finetuned-hate_speech'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["# how to share the model you created\n","\n","AutoModelForSequenceClassification.from_pretrained(\"Dc26/distilbert-base-uncased-finetuned-hate_speech\")"],"metadata":{"id":"1GLqcA-7Td12"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hyperparameter search\n","\n","install optuna and raytune cause it's used for hyper parameter tuning\n","\n","we also defined a new model using the ```new_model```, so we create a new model every time"],"metadata":{"id":"Go0I7MsaL8j6"}},{"cell_type":"code","source":["num_labels=3\n","def new_model():\n","    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"],"metadata":{"id":"Au50QuA6L85W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model_init=new_model,\n","    args=args,\n","    train_dataset=dataset_proc[\"train\"],\n","    eval_dataset=dataset_proc[\"test\"],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"metadata":{"id":"f8m3I9xVL87-","executionInfo":{"status":"ok","timestamp":1679665940172,"user_tz":-480,"elapsed":4008,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e0a71cd7-c5b2-423b-cabe-5092ccddfec5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/content/distilbert-base-uncased-finetuned-hate_speech is already a clone of https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech. Make sure you pull the latest changes with `repo.git_pull()`.\n","WARNING:huggingface_hub.repository:/content/distilbert-base-uncased-finetuned-hate_speech is already a clone of https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech. Make sure you pull the latest changes with `repo.git_pull()`.\n"]}]},{"cell_type":"markdown","source":["hyperparameter search  may take a long time to run on the full dataset so \n","- it only runs on 1/10th of the dataset\n","- only train the full dataset on the best perfoming one"],"metadata":{"id":"3OaOs8EdZE-W"}},{"cell_type":"code","source":["train_dataset = dataset_proc[\"train\"].shard(index=1, num_shards=10) "],"metadata":{"id":"m0ipxlg7L8-f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# returns Best Run object which mazimizes the accuracy/ desired metric\n","best_run = trainer.hyperparameter_search(n_trials=5, direction=\"maximize\")"],"metadata":{"id":"l-kotbZbL9Aw","executionInfo":{"status":"error","timestamp":1679665954400,"user_tz":-480,"elapsed":2202,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"colab":{"base_uri":"https://localhost:8080/","height":991},"outputId":"eeb2c7b8-6e49-46e5-bc0f-e11c761dfaca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-03-24 13:52:31,865]\u001b[0m A new study created in memory with name: no-name-ff8d76f1-4d8e-4de7-8c98-6d7d79c9d77e\u001b[0m\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[33m[W 2023-03-24 13:52:33,279]\u001b[0m Trial 0 failed with parameters: {'learning_rate': 2.7358513247381042e-05, 'num_train_epochs': 1, 'seed': 6, 'per_device_train_batch_size': 32} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 14.75 GiB total capacity; 13.65 GiB already allocated; 4.81 MiB free; 13.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF').\u001b[0m\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","  File \"/usr/local/lib/python3.9/dist-packages/transformers/integrations.py\", line 187, in _objective\n","    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n","  File \"/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\", line 1627, in train\n","    self._move_model_to_device(self.model, args.device)\n","  File \"/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\", line 716, in _move_model_to_device\n","    model = model.to(device)\n","  File \"/usr/local/lib/python3.9/dist-packages/transformers/modeling_utils.py\", line 1811, in to\n","    return super().to(*args, **kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 989, in to\n","    return self._apply(convert)\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 641, in _apply\n","    module._apply(fn)\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 641, in _apply\n","    module._apply(fn)\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 641, in _apply\n","    module._apply(fn)\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 664, in _apply\n","    param_applied = fn(param)\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 987, in convert\n","    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n","torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 14.75 GiB total capacity; 13.65 GiB already allocated; 4.81 MiB free; 13.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","\u001b[33m[W 2023-03-24 13:52:33,281]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-5671481c44c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# returns Best Run object which mazimizes the accuracy/ desired metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameter_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mhyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m   2536\u001b[0m             \u001b[0mHPSearchBackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWANDB\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_hp_search_wandb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m         }\n\u001b[0;32m-> 2538\u001b[0;31m         \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_search_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/integrations.py\u001b[0m in \u001b[0;36mrun_hp_search_optuna\u001b[0;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_jobs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBestRun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/integrations.py\u001b[0m in \u001b[0;36m_objective\u001b[0;34m(trial, checkpoint_dir)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0;31m# If there hasn't been any evaluation during the training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_reloaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_model_on_device\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1627\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_wrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;31m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tie_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1809\u001b[0m             )\n\u001b[1;32m   1810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1811\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     def register_backward_hook(\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    985\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    986\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 987\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 14.75 GiB total capacity; 13.65 GiB already allocated; 4.81 MiB free; 13.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["# best_run"],"metadata":{"id":"C1hRCnFgL9Cp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can customize the objective to maximize by passing along a `compute_objective` function to the `hyperparameter_search` method, and you can customize the search space by passing a `hp_space` argument to `hyperparameter_search`. See this [forum post](https://discuss.huggingface.co/t/using-hyperparameter-search-in-trainer/785/10) for some examples.\n","\n","To reproduce the best training, just set the hyperparameters in your `TrainingArgument` before creating a `Trainer`:"],"metadata":{"id":"JOgeUHo6ZrB7"}},{"cell_type":"code","source":["for n, v in best_run.hyperparameters.items():\n","    setattr(trainer.args, n, v)\n","\n","trainer.train()"],"metadata":{"id":"EGU6am0HZrUu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["check if the model workds"],"metadata":{"id":"ttVZ_PZf5RnY"}},{"cell_type":"code","source":["train[\"label\"].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gGRzhnI35R1Q","executionInfo":{"status":"ok","timestamp":1679671174516,"user_tz":-480,"elapsed":278,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"07376cc2-dae2-4b6f-83e6-75fce6d8fc8f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    15324\n","2    3376 \n","0    1126 \n","Name: label, dtype: int64"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["test[\"label\"].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qT_Sqiy25Ug-","executionInfo":{"status":"ok","timestamp":1679667714207,"user_tz":-480,"elapsed":285,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"68394241-3147-4156-ee38-2bb879c5b546"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    3841\n","2    824 \n","0    292 \n","Name: label, dtype: int64"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["from transformers import TextClassificationPipeline\n","os.environ['CUDA_VISIBLE_DEVICES'] ='0'\n","\n","current_model = AutoModelForSequenceClassification.from_pretrained(\"Dc26/distilbert-base-uncased-finetuned-hate_speech\")\n","pipe = TextClassificationPipeline(model=current_model, tokenizer=tokenizer, return_all_scores=False)\n","\n","\n","def get_prediction(text):\n","  return pipe(text)[-1][\"label\"][-1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5IEJx3ETAuCp","executionInfo":{"status":"ok","timestamp":1679671791219,"user_tz":-480,"elapsed":1663,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"cb887310-4b93-41cb-a073-7fca8f0c0009"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["%%time\n","test[\"predicted\"] = test[\"tweet\"].apply(lambda x: get_prediction(x))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s--csHxMAuI-","executionInfo":{"status":"ok","timestamp":1679672159114,"user_tz":-480,"elapsed":367902,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"bf919624-0eb3-410c-813f-ae407042fa85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 5min 55s, sys: 737 ms, total: 5min 56s\n","Wall time: 6min 7s\n"]}]},{"cell_type":"code","source":["## create a confusion matrix\n","test[\"predicted\"] = test[\"predicted\"].astype(int)\n","test.groupby([\"predicted\", \"label\"]).size().unstack(fill_value=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"8TEBtSUTJm4e","executionInfo":{"status":"ok","timestamp":1679672159115,"user_tz":-480,"elapsed":16,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"ca09f1f4-d674-4e09-a872-8e7e21b94258"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["label        0     1    2\n","predicted                \n","0          87   65    3  \n","1          177  3724  47 \n","2          40   77    737"],"text/html":["\n","  <div id=\"df-c6abca82-f35c-4e35-b616-1b68d047175e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>label</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","    <tr>\n","      <th>predicted</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>87</td>\n","      <td>65</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>177</td>\n","      <td>3724</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>40</td>\n","      <td>77</td>\n","      <td>737</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6abca82-f35c-4e35-b616-1b68d047175e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c6abca82-f35c-4e35-b616-1b68d047175e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c6abca82-f35c-4e35-b616-1b68d047175e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":103}]},{"cell_type":"code","source":["import seaborn as sns\n","test.groupby([\"predicted\", \"label\"]).size().unstack(fill_value=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"wFnvtawOUD4D","executionInfo":{"status":"ok","timestamp":1679673079886,"user_tz":-480,"elapsed":402,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"d951edd2-cd80-43b2-8c45-ec59da117f0b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["label        0     1    2\n","predicted                \n","0          87   65    3  \n","1          177  3724  47 \n","2          40   77    737"],"text/html":["\n","  <div id=\"df-9285367e-2024-43ac-bb62-982ea9e21c71\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>label</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","    <tr>\n","      <th>predicted</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>87</td>\n","      <td>65</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>177</td>\n","      <td>3724</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>40</td>\n","      <td>77</td>\n","      <td>737</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9285367e-2024-43ac-bb62-982ea9e21c71')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9285367e-2024-43ac-bb62-982ea9e21c71 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9285367e-2024-43ac-bb62-982ea9e21c71');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":109}]},{"cell_type":"code","source":["test[\"predicted\"].value_counts()\n","# cause tpp much 2 data predicted everything as 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MEQK3YAQLXXF","executionInfo":{"status":"ok","timestamp":1679672159115,"user_tz":-480,"elapsed":15,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"24c56f8c-65dc-456f-b467-22d375afddf2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    3948\n","2    854 \n","0    155 \n","Name: predicted, dtype: int64"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["test[test[\"predicted\"]==test[\"label\"]].shape[0] / test.shape[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmByfJ9fKxYE","executionInfo":{"status":"ok","timestamp":1679673006929,"user_tz":-480,"elapsed":3,"user":{"displayName":"Diane Cruz","userId":"05838927147744389195"}},"outputId":"a790f59d-45f6-4c8a-eef2-c6e12a15a490"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.917490417591285"]},"metadata":{},"execution_count":105}]},{"cell_type":"code","source":[],"metadata":{"id":"IMfof5x5MQ5S","executionInfo":{"status":"ok","timestamp":1680098588743,"user_tz":-480,"elapsed":3,"user":{"displayName":"Diane Kathryn Cruz","userId":"08869112525818712386"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Reccomendation\n","\n","1. Further data cleaning\n","  - looking at the tweets since there are a lot of emojis so, maybe the performance could have been better if we remove emojis and done further cleaning\n","  - remove @username and make a generic tag instead of the model seeing different username\n","2.  test on the if the model would be better with the undersampling and over sample datasets\n","3. Graph the confusion matrix of the test set\n","4. Compare performance with an existing paper (papers: https://github.com/aymeam/Datasets-for-Hate-Speech-Detection)"],"metadata":{"id":"BKSkHlmMAMZ4"}},{"cell_type":"code","source":[],"metadata":{"id":"XbQWPx-t7r9y"},"execution_count":null,"outputs":[]}]}