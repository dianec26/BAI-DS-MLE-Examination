{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pREHsp2nss1m"
   },
   "source": [
    "Notebook objectives:\n",
    "- Fine-tune a HuggingFace model for text classification by following this documentation. Below are the specifications:\n",
    "  - Make use of Google Colabâ€™s free GPU to train a HuggingFace model\n",
    "  - Follow the documentation from start to finish\n",
    "  - Be able to answer questions about each piece of code during the interview\n",
    "  - Demonstrate fine-tuning using the sample dataset provided.\n",
    "  - Bonus points: Use another text classification dataset to perform fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLZA46rtupEN"
   },
   "source": [
    "\n",
    "# Project 1: Text classification\n",
    "\n",
    "## Project objective\n",
    "- Fine-tune a HuggingFace model for text classification \n",
    "\n",
    "## Set up install the following:\n",
    "- transformers: model used for text classification\n",
    "- dataset: library to download GLUE datasets\n",
    "- Git-LFS\n",
    "\n",
    "-  using  a pre trained SST-2 (Standford Sentiment Analysis Treebank) that determines  if a sentence is positive or neative\n",
    "\n",
    "- using [hate-speech-data](https://huggingface.co/datasets/hate_speech_offensive) to finetune the model to predict if the text is hate speech\n",
    "\n",
    "Objecttive for part 2:\n",
    "- Social media and messaging platforms have given us the ability to connect and express ourselves freely. However, what happens when these platforms are used to spread negativity and hate? \n",
    "- That's where the Hater_classifier comes in. This tool is designed to identify hateful speech on social media, possibly filtering out the negativity making it a powerful tool for creating a more positive online environment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67659,
     "status": "ok",
     "timestamp": 1679669685395,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "BqM4I0S_upQq",
    "outputId": "d5fde3fe-279b-4ec0-fb40-a8c15d2b975f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.27.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.10.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: requests in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: datasets in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.24.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.10.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: torch in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.10.6)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (3.1.0)\n",
      "Requirement already satisfied: optuna in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (1.10.2)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (0.9.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (2.0.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement ray[tune] (from versions: none)\n",
      "ERROR: No matching distribution found for ray[tune]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.post1)\n",
      "Requirement already satisfied: pynvml in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (11.5.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install  transformers\n",
    "! pip install datasets\n",
    "! pip install torch\n",
    "! pip install imbalanced-learn\n",
    "! pip install optuna\n",
    "! pip install ray[tune]\n",
    "! pip install sklearn\n",
    "! pip install pynvml "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gitlfs\n",
    "\n",
    "- Issue with git, everytime you replace assets(new version of an image) in git it's compressed in the snapshot, repo keeps storage higher and slower so instead of pushing the media assets in the gihub. the Gitlfs would push the media in the ```lfs server``` instead of the repo\n",
    "- don't need to use gitlfs cause don't have csvs for this example\n",
    "- source: https://www.youtube.com/watch?v=jXsvFfksvd0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.0.6-py3-none-any.whl (138 kB)\n",
      "     ---------------------------------------- 0.0/138.3 kB ? eta -:--:--\n",
      "     ----------------- --------------------- 61.4/138.3 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 138.3/138.3 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (6.22.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (8.11.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (5.9.0)\n",
      "Collecting widgetsnbextension~=4.0.7\n",
      "  Downloading widgetsnbextension-4.0.7-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.1/2.1 MB 1.7 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.2/2.1 MB 1.8 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 0.2/2.1 MB 1.5 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.3/2.1 MB 1.5 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 0.4/2.1 MB 1.6 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 0.4/2.1 MB 1.6 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 0.5/2.1 MB 1.5 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 0.6/2.1 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 0.7/2.1 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 0.7/2.1 MB 1.5 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 0.8/2.1 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.9/2.1 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 1.0/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 1.1/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.1/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 1.2/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.3/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 1.4/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.4/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.5/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.6/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.6/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.7/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.8/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 1.9/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.0/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.0/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.1/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting jupyterlab-widgets~=3.0.7\n",
      "  Downloading jupyterlab_widgets-3.0.7-py3-none-any.whl (198 kB)\n",
      "     ---------------------------------------- 0.0/198.2 kB ? eta -:--:--\n",
      "     ------------ -------------------------- 61.4/198.2 kB 3.4 MB/s eta 0:00:01\n",
      "     ----------------------- -------------- 122.9/198.2 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 198.2/198.2 kB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.6)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (8.1.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.4)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (25.0.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (306)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\kat\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.0.6 jupyterlab-widgets-3.0.7 widgetsnbextension-4.0.7\n"
     ]
    }
   ],
   "source": [
    "# ! pip install git-lfs\n",
    "!pip install tqdm\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oL12MX3HDMag"
   },
   "source": [
    "import all the libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PawQaIib6XE0"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "import pandas as pd\n",
    "import torch\n",
    "# import datasets\n",
    "from datasets import load_dataset, load_metric, Dataset, DatasetDict\n",
    "# from transformers import AutoTokenizer\n",
    "import transformers\n",
    "from transformers import AutoTokenizer,Trainer,AutoModelForSequenceClassification, TrainingArguments\n",
    "from transformers.utils import send_example_telemetry\n",
    "# import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for gpu util\n",
    "from pynvml import * \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLV6LolAL14f"
   },
   "source": [
    "define functions to track GPU utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fimrPAgmL2Fd"
   },
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqJ6okqIMlkR"
   },
   "source": [
    "Get your hugging face api in https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416,
     "referenced_widgets": [
      "1de3ef734af54e9084ba6d24ad2b9573",
      "66631f3e7c72429f8d5d5145f3158676",
      "81011b5150904e2fa994ae7deeb8edae",
      "e5eff094c0644c69ad9e5d3a31a3f452",
      "9c9f7251c0e941e7a63f7f9a8323cfa9",
      "8f1e4282e29643ed8225f2bf1028056f",
      "eda9f24f0ff243cfbd6878a75e927d07",
      "85baed07f8c94ed196c374a6e58e22cc",
      "fcf7279ba53b440abe3896b38ef0cc6f",
      "31d82894dc4a4f8b927e78d00950e39b",
      "c55401d4c2c04e7698935c9d8c763355",
      "c5d3dd1626674485b1665c78e64d7510",
      "0a13584b9f134dfa97ca691f8eddd434",
      "5e5be5a0971640c7b2391691f809da88",
      "6e45ce4dc1c145468284c1c8c0ec6939",
      "37b872d373cc48bb994ab6d312557c13",
      "90763fb40fda44dba79088228c7808e0"
     ]
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1679669714738,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "d5VYN9dkvUA9",
    "outputId": "3c7f2c08-d274-4322-aa82-950c239e5051"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee791e65a95e43f2a47829c9ae4607b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log in ito  hugging face\n",
    "notebook_login()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1679669718190,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "LF7NkEKvvidQ",
    "outputId": "c3ab01e3-9bd2-4933-9e70-793f49931670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.27.3\n"
     ]
    }
   ],
   "source": [
    "# show the version on the tranformer\n",
    "# since transform is > 4.11.0 there is no issue\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7HBKjDjP2OlR"
   },
   "outputs": [],
   "source": [
    "send_example_telemetry(\"text_classification_notebook\", framework=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xx75ZPy5-dL1"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GO2lfsx-MY-n"
   },
   "source": [
    "### Model Definition\n",
    "Pick a model from the [Model Hub](https://huggingface.co/models) with a  clasffification head \n",
    "\n",
    "Adjust the batch size as needed to not run out of memory\n",
    "\n",
    "why choose distilbert-base-uncased with the task of sst2?\n",
    "- sst2/sentiment analysis, can help identify the hate speech\n",
    "- distilbert-base-uncased: 110m Params compared other bert-large-uncased which is  3x more (340M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fJ5TKp8IMX-i"
   },
   "outputs": [],
   "source": [
    "task = \"hate_speech_detection\"\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16\n",
    "\n",
    "# from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "# model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# with torch.no_grad():\n",
    "#     logits = model(**inputs).logits\n",
    "\n",
    "# predicted_class_id = logits.argmax().item()\n",
    "# model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcYxsUZa3kD_"
   },
   "source": [
    "### Loading the existing model's dataset\n",
    "\n",
    "Picking a dataset:\n",
    "- [SST-2](https://nlp.stanford.edu/sentiment/index.html) (Stanford Sentiment Treebank) Determine if the sentence has a positive or negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "210483cad01847e58be29f530e5ee8cb",
      "4e56946c90214f27a89a16113cea861d",
      "5417a60f28be450a8cc7938dfa12e0a2",
      "46e7cba5323643189a971b32fd0bb809",
      "a9adb03db8d04ce9852e852d40cd841f",
      "dd8ddd6f20114f3d8b09b872d27cbc60",
      "b4831d3b79f449d89495fc7f11f4df93",
      "9bc1ba4b9d2345a98a594a4b05dbc293",
      "ba6675b2cea34a0c8cb08a39f2844d40",
      "32d5648aa6e44e0e96929fc91fc999d5",
      "7ba70446b54341ccb46d9cb5cc3f4105"
     ]
    },
    "executionInfo": {
     "elapsed": 2909,
     "status": "ok",
     "timestamp": 1679669724328,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "idoucMRc3V7r",
    "outputId": "03efe795-e7ba-4148-c322-c2aaa7d92cca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.8k/28.8k [00:00<00:00, 92.7kB/s]\n",
      "Downloading metadata: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.7k/28.7k [00:00<00:00, 114kB/s]\n",
      "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27.9k/27.9k [00:00<00:00, 101kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/sst2 to C:/Users/Kat/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.44M/7.44M [00:06<00:00, 1.13MB/s]\n",
      "                                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to C:/Users/Kat/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 73.11it/s]\n",
      "C:\\Users\\Kat\\AppData\\Local\\Temp\\ipykernel_26620\\235830681.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric('glue', actual_task)\n",
      "Downloading builder script: 5.76kB [00:00, 2.88MB/s]                                                                \n"
     ]
    }
   ],
   "source": [
    "existing_tasks = [\"cola\", \"mnli\", \"mnli-mm\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]\n",
    "\n",
    "actual_task = \"sst2\"\n",
    "data = load_dataset(\"glue\", actual_task)\n",
    "metric = load_metric('glue', actual_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XedHI5xshhh"
   },
   "outputs": [],
   "source": [
    "# metric[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1679669724329,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "hAKuOITC71cN",
    "outputId": "83e23c0d-ce32-4b5e-b2cd-f05ad5e282d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': 'hide new secretions from the parental units ',\n",
       " 'label': 0,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the dictionary format of the data\n",
    "display(data)\n",
    "\n",
    "#checking what the first entry in train\n",
    "data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LgQted68YV-"
   },
   "source": [
    "Pick random entries to get a sense of what the data looks like\n",
    "1. turn the into dataset object into a dataframae so you can get samples from it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 9117,
     "status": "ok",
     "timestamp": 1679669735300,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "-XYz3Rap8Yl1",
    "outputId": "65d2d6ab-c4e9-4bd0-e9d6-0a22767ce02b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63192</th>\n",
       "      <td>'ll feel as the credits roll</td>\n",
       "      <td>1</td>\n",
       "      <td>63192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26154</th>\n",
       "      <td>goldbacher draws on an elegant visual sense an...</td>\n",
       "      <td>1</td>\n",
       "      <td>26154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42779</th>\n",
       "      <td>be commended for illustrating the merits of fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>42779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25720</th>\n",
       "      <td>astonishingly skillful and moving ... it could...</td>\n",
       "      <td>1</td>\n",
       "      <td>25720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27512</th>\n",
       "      <td>is a lot like a well-made pb &amp; j sandwich : fa...</td>\n",
       "      <td>1</td>\n",
       "      <td>27512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60129</th>\n",
       "      <td>dismiss --</td>\n",
       "      <td>0</td>\n",
       "      <td>60129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24560</th>\n",
       "      <td>original and insightful</td>\n",
       "      <td>1</td>\n",
       "      <td>24560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41458</th>\n",
       "      <td>wretchedly unfunny wannabe</td>\n",
       "      <td>0</td>\n",
       "      <td>41458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15032</th>\n",
       "      <td>few movies are able to accomplish</td>\n",
       "      <td>1</td>\n",
       "      <td>15032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>the biggest disappointments of the year</td>\n",
       "      <td>0</td>\n",
       "      <td>5687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label    idx\n",
       "63192                      'll feel as the credits roll       1  63192\n",
       "26154  goldbacher draws on an elegant visual sense an...      1  26154\n",
       "42779  be commended for illustrating the merits of fi...      1  42779\n",
       "25720  astonishingly skillful and moving ... it could...      1  25720\n",
       "27512  is a lot like a well-made pb & j sandwich : fa...      1  27512\n",
       "60129                                        dismiss --       0  60129\n",
       "24560                           original and insightful       1  24560\n",
       "41458                        wretchedly unfunny wannabe       0  41458\n",
       "15032                 few movies are able to accomplish       1  15032\n",
       "5687            the biggest disappointments of the year       0   5687"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data[\"train\"]).sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TWkX00_H-e5"
   },
   "source": [
    "### Loading the data for hate speech\n",
    "\n",
    "data description (based on github):\n",
    "- hate_speech = number of CF users who judged the tweet to be hate speech.\n",
    "\n",
    "- offensive_language = number of CF users who judged the tweet to be offensive.\n",
    "\n",
    "- neither = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n",
    "\n",
    "- class = class label for majority of CF users. \n",
    "  - 0 - hate speech \n",
    "  - 1 - offensive language \n",
    "  - 2 - neither\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "4983fb7c2cca461fb5539e73cccd6ac7",
      "ec953004e4534ac68da1efba05da22b2",
      "fe72c604335b42d895dd3ce73348a057",
      "86149739912d4bf7a46949063be7b2bc",
      "10f1b68b08f141a8bcbd55adab4e7821",
      "a2925e1f42b04317a660d91d4f622fce",
      "b984373baa084d959c74f810100f3a67",
      "9149d8e855694b8294debd55b71a53d1",
      "16ed605b5cb441758581fe9c80ffac1d",
      "7dae63d1f4fb4c8c89725b2d7a8d5f51",
      "a222ab21d8c04314918778412ac91e77"
     ]
    },
    "executionInfo": {
     "elapsed": 1607,
     "status": "ok",
     "timestamp": 1679669736902,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "-OXEHQPe3yG2",
    "outputId": "4da73031-3346-49dd-f7e4-1fc24411bae4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.48k/3.48k [00:00<00:00, 3.48MB/s]\n",
      "Downloading metadata: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.82k/1.82k [00:00<00:00, 910kB/s]\n",
      "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.83k/5.83k [00:00<00:00, 5.83MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset hate_speech_offensive/default to C:/Users/Kat/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 2.55MB [00:00, 3.80MB/s]                                                                          \n",
      "                                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset hate_speech_offensive downloaded and prepared to C:/Users/Kat/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 99.90it/s]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "dataset_name = \"hate_speech_offensive\"\n",
    "\n",
    "hate_speech_ds  = load_dataset(dataset_name)\n",
    "# hate_speech = pd.read_csv(\"hate_speech_labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "C2ju11DEp7Nw"
   },
   "outputs": [],
   "source": [
    "hate_speech_df = pd.DataFrame(hate_speech_ds[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkitdRToqdd0"
   },
   "outputs": [],
   "source": [
    "# hate_speech_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hyfR7plZ4h0"
   },
   "source": [
    "Showing some samples of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1679669740911,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "Sjt7GXArZ6NP",
    "outputId": "302f033b-c581-4ee4-f263-09cabae60f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate speech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kat\\AppData\\Local\\Temp\\ipykernel_26620\\2985035471.py:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16595</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @NYTMinusContext: kill whitey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3815</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kevin_McAdams Because Ian's retarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4725</th>\n",
       "      <td>0</td>\n",
       "      <td>@SoftestMuffin @_tee13 @TorahBlaze Best believe We aint no christian slave brainwash black spooks miss white man, unlike yoself, she devil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10653</th>\n",
       "      <td>0</td>\n",
       "      <td>I like Chinese buffets but I hate all the chinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>0</td>\n",
       "      <td>Bill Smith DDS MTV ODB LGBTQ MMA NFL AFLCIO \\n\\nbitch pick one.\\n\\nFucking hate you.\\n\\nI know you proud but shit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>0</td>\n",
       "      <td>@erinscafe We hate the Yankees though, right? I feel like I'm really good at hating them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>0</td>\n",
       "      <td>@Taylor_1017 faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13319</th>\n",
       "      <td>0</td>\n",
       "      <td>Niggas be in they feelings when they find out their hoe fuckin another nigga #StopSavinTheseHoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18483</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @_politeASSHOLE: 4) Only pussy niggas who suck dick cry about someone being in their mentions, tweet the person then cry again about the&amp;#8230;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4657</th>\n",
       "      <td>0</td>\n",
       "      <td>@SchulzGrayson @Dswizzle3 oh woulda coulda shoulda ass niggas bitch ass nigga, what u bout oh ban wagging ass nigga catch your phase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  \\\n",
       "16595  0       \n",
       "3815   0       \n",
       "4725   0       \n",
       "10653  0       \n",
       "8034   0       \n",
       "5939   0       \n",
       "4856   0       \n",
       "13319  0       \n",
       "18483  0       \n",
       "4657   0       \n",
       "\n",
       "                                                                                                                                                    tweet  \n",
       "16595  RT @NYTMinusContext: kill whitey                                                                                                                    \n",
       "3815   @Kevin_McAdams Because Ian's retarded                                                                                                               \n",
       "4725   @SoftestMuffin @_tee13 @TorahBlaze Best believe We aint no christian slave brainwash black spooks miss white man, unlike yoself, she devil          \n",
       "10653  I like Chinese buffets but I hate all the chinks                                                                                                    \n",
       "8034   Bill Smith DDS MTV ODB LGBTQ MMA NFL AFLCIO \\n\\nbitch pick one.\\n\\nFucking hate you.\\n\\nI know you proud but shit.                                  \n",
       "5939   @erinscafe We hate the Yankees though, right? I feel like I'm really good at hating them.                                                           \n",
       "4856   @Taylor_1017 faggot                                                                                                                                 \n",
       "13319  Niggas be in they feelings when they find out their hoe fuckin another nigga #StopSavinTheseHoes                                                    \n",
       "18483  RT @_politeASSHOLE: 4) Only pussy niggas who suck dick cry about someone being in their mentions, tweet the person then cry again about the&#8230;  \n",
       "4657   @SchulzGrayson @Dswizzle3 oh woulda coulda shoulda ass niggas bitch ass nigga, what u bout oh ban wagging ass nigga catch your phase                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "Offensive language\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12286</th>\n",
       "      <td>1</td>\n",
       "      <td>LMFAOOOOOO GAY AS FUCK RT @PubesOnFleeK: &amp;#128557;&amp;#128557;&amp;#128557;&amp;#128557;&amp;#128557; get these two faggots off my TL http://t.co/oKUMmSJEYi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19531</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @lildurk_: I'm finna up my bag so I'm cutting you weak hoes off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10945</th>\n",
       "      <td>1</td>\n",
       "      <td>I tell the 5th bitch to get the 6th bitch to to have the 7th bitch bring more.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12248</th>\n",
       "      <td>1</td>\n",
       "      <td>Kissing that bitch but she sucking me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>1</td>\n",
       "      <td>Bruh leave it to the coins coons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12284</th>\n",
       "      <td>1</td>\n",
       "      <td>LMFAOO somebody commented on my book saying I need Medical Attention bitch you the one reading it &amp;#128514;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18784</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @collegefession: \"Guy tells me he doesn't eat pussy, and all of the sudden I don't suck dick anymore\" - Centeral Washington University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19745</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @nhalegood: When hoes feel like their photo didnt get enough favorites http://t.co/Gi3xXzBbq9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#8220;@CayMarieee: &amp;#8220;@WhereYoHussleAt: @CayMarieee bitch&amp;#8221; what u gone say bitch for. We're on the phone bitch.&amp;#8221; Cuz to the let these Mfs know &amp;#128514;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11297</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm in the cut with my old boys and this bitch asks me to smoke weed with her in a fucking Yaris. The fuck? Lol hell no.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  \\\n",
       "12286  1       \n",
       "19531  1       \n",
       "10945  1       \n",
       "12248  1       \n",
       "8207   1       \n",
       "12284  1       \n",
       "18784  1       \n",
       "19745  1       \n",
       "1170   1       \n",
       "11297  1       \n",
       "\n",
       "                                                                                                                                                                           tweet  \n",
       "12286  LMFAOOOOOO GAY AS FUCK RT @PubesOnFleeK: &#128557;&#128557;&#128557;&#128557;&#128557; get these two faggots off my TL http://t.co/oKUMmSJEYi                              \n",
       "19531  RT @lildurk_: I'm finna up my bag so I'm cutting you weak hoes off                                                                                                         \n",
       "10945  I tell the 5th bitch to get the 6th bitch to to have the 7th bitch bring more.                                                                                             \n",
       "12248  Kissing that bitch but she sucking me                                                                                                                                      \n",
       "8207   Bruh leave it to the coins coons                                                                                                                                           \n",
       "12284  LMFAOO somebody commented on my book saying I need Medical Attention bitch you the one reading it &#128514;                                                                \n",
       "18784  RT @collegefession: \"Guy tells me he doesn't eat pussy, and all of the sudden I don't suck dick anymore\" - Centeral Washington University                                  \n",
       "19745  RT @nhalegood: When hoes feel like their photo didnt get enough favorites http://t.co/Gi3xXzBbq9                                                                           \n",
       "1170   &#8220;@CayMarieee: &#8220;@WhereYoHussleAt: @CayMarieee bitch&#8221; what u gone say bitch for. We're on the phone bitch.&#8221; Cuz to the let these Mfs know &#128514;  \n",
       "11297  I'm in the cut with my old boys and this bitch asks me to smoke weed with her in a fucking Yaris. The fuck? Lol hell no.                                                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "Neither\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18558</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @amoz1939: drinking\\nto the last drop\\nwashing teapot \\n#haiku #mijikai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12474</th>\n",
       "      <td>2</td>\n",
       "      <td>Little things can just kill a negros mood man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18977</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @espn: Hot off the press, here&amp;#8217;s Todd McShay&amp;#8217;s first post-Combine NFL mock draft, including a new No. 1. http://t.co/su5ixWrthq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5528</th>\n",
       "      <td>2</td>\n",
       "      <td>@antiamnesty @AppSame @WhiteHouse \\nI agree 100%. No naturalized citizenship, no anchor baby amnesty. All go to parents country of origin.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2</td>\n",
       "      <td>\"@OSAY_it_aint_so: &amp;#8220;@IgnoreAllLaws: Fosters home for imaginary trash&amp;#8221; WHOA CHILL\"\\n\\nthat show was everything tf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>2</td>\n",
       "      <td>#Yankees #FireCashman I don't want Arod back.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7072</th>\n",
       "      <td>2</td>\n",
       "      <td>@spence1reed_ bro , i heard slaughter songs .. they all trash .. they just freestylers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11453</th>\n",
       "      <td>2</td>\n",
       "      <td>ISIS Supporters in America: The Jihadis Next Door http://t.co/u0YHWkD34c http://t.co/0XHPbRL9EQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10158</th>\n",
       "      <td>2</td>\n",
       "      <td>I could go for a brownie right now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405</th>\n",
       "      <td>2</td>\n",
       "      <td>@Hovaa_ your pet zebra. stripey?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  \\\n",
       "18558  2       \n",
       "12474  2       \n",
       "18977  2       \n",
       "5528   2       \n",
       "205    2       \n",
       "805    2       \n",
       "7072   2       \n",
       "11453  2       \n",
       "10158  2       \n",
       "3405   2       \n",
       "\n",
       "                                                                                                                                                tweet  \n",
       "18558  RT @amoz1939: drinking\\nto the last drop\\nwashing teapot \\n#haiku #mijikai                                                                      \n",
       "12474  Little things can just kill a negros mood man                                                                                                   \n",
       "18977  RT @espn: Hot off the press, here&#8217;s Todd McShay&#8217;s first post-Combine NFL mock draft, including a new No. 1. http://t.co/su5ixWrthq  \n",
       "5528   @antiamnesty @AppSame @WhiteHouse \\nI agree 100%. No naturalized citizenship, no anchor baby amnesty. All go to parents country of origin.      \n",
       "205    \"@OSAY_it_aint_so: &#8220;@IgnoreAllLaws: Fosters home for imaginary trash&#8221; WHOA CHILL\"\\n\\nthat show was everything tf                    \n",
       "805    #Yankees #FireCashman I don't want Arod back.                                                                                                   \n",
       "7072   @spence1reed_ bro , i heard slaughter songs .. they all trash .. they just freestylers                                                          \n",
       "11453  ISIS Supporters in America: The Jihadis Next Door http://t.co/u0YHWkD34c http://t.co/0XHPbRL9EQ                                                 \n",
       "10158  I could go for a brownie right now                                                                                                              \n",
       "3405   @Hovaa_ your pet zebra. stripey?                                                                                                                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#adding to expand the tweet to see the full text\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "print(\"Hate speech\")\n",
    "display(hate_speech_df[hate_speech_df[\"class\"]==0].sample(10)[[\"class\",\"tweet\"]])\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Offensive language\")\n",
    "display(hate_speech_df[hate_speech_df[\"class\"]==1].sample(10)[[\"class\",\"tweet\"]])\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "print(\"Neither\")\n",
    "print()\n",
    "display(hate_speech_df[hate_speech_df[\"class\"]==2].sample(10)[[\"class\",\"tweet\"]])\n",
    "print(\"-----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8LOMx13Ih3J"
   },
   "source": [
    "Dataset observations:\n",
    "1. Majority (77%) of the examples are  offensive language \n",
    "2. We rarely find hate speech having only 1430 examples (5% of the whole dataset)\n",
    "\n",
    "Possible experiments:\n",
    "- Rebalance the dataset via:\n",
    "  - oversampling \n",
    "  - undersampling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WklD5NVZZgT4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1679669740911,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "sSKQqmbFHX5S",
    "outputId": "4303870e-35d0-4b4d-f526-fa05ddbf3ad0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.774321\n",
       "2    0.167978\n",
       "0    0.057701\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of the classes\n",
    "hate_speech_df[\"class\"].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ogc7l71EZvaV"
   },
   "source": [
    "check for nulls and drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "kYi5zFSdZxCv"
   },
   "outputs": [],
   "source": [
    "hate_speech_df.isna().sum()\n",
    "hate_speech_df = hate_speech_df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYlmfg7Kj_yz"
   },
   "source": [
    "\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JXwR7Li3qkt"
   },
   "source": [
    "### Tokenize\n",
    "\n",
    "1. Defining the tokenizer (tokenizer is a method or process to convert the words into numbers such that the computer can understand it)\n",
    "\n",
    "2. sample of the tokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1679669740912,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "unsIv2ga3i4s",
    "outputId": "45ac2c9c-eff5-4f83-e25d-fa6a24c8464c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.0/28.0 [00:00<00:00, 28.0kB/s]\n",
      "C:\\Users\\Kat\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kat\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [00:00<00:00, 483kB/s]\n",
      "Downloading (â€¦)solve/main/vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:03<00:00, 63.2kB/s]\n",
      "Downloading (â€¦)/main/tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466k/466k [00:04<00:00, 99.8kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2009, 1005, 1055, 2033, 1010, 7632, 1010, 1045, 1005, 1049, 1996, 3291, 1010, 2009, 1005, 1055, 2033, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a toeknizer that fits the model in this case bert-distil-uncase\n",
    "#use the vocab of the pretrained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "#input is the id in of the vocabulary \n",
    "tokenizer(\"it's me, hi, I'm the problem, it's me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nwFsc1i4Dzf"
   },
   "source": [
    "tokenize curse words or profanity to check what's the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1679670111075,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "zmzrd75e4I0N",
    "outputId": "4271933f-f62f-4b62-f1d6-cdbd60ab74b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 6904, 13871, 4140, 102], 'attention_mask': [1, 1, 1, 1, 1]}\n",
      "{'input_ids': [101, 7743, 102], 'attention_mask': [1, 1, 1]}\n",
      "{'input_ids': [101, 7743, 102], 'attention_mask': [1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(\"faggot\"))\n",
    "print(tokenizer(\"bitch\"))\n",
    "print(tokenizer(\"bitch\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2CvvZe-7OxL"
   },
   "source": [
    "\n",
    "<!-- After tokenzing,use pytorch to train the model to take advantage of colab free gpu:\n",
    "\n",
    "- video source: https://youtu.be/Dh9CL8fyG80\n",
    "- link source: https://youtu.be/Dh9CL8fyG80 -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1679670111076,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "CbIipGEz7N-z",
    "outputId": "a3f4c78c-14fe-480e-ed30-8a69ff1db297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: hide new secretions from the parental units \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# sentence1_key, sentence2_key = task_to_keys[task]\n",
    "sentence1_key = \"sentence\"\n",
    "\n",
    "#print the sentence\n",
    "print(f\"Sentence: {data['train'][0][sentence1_key]}\")\n",
    "\n",
    "#print the tokenized sentence \n",
    "tokenizer(data['train'][0][sentence1_key],truncation=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHgX_OBkWI9D"
   },
   "source": [
    "Change the sample code since we're using ```sst2``` only, which means we only need sentence column. I'm using a different dataset so the ```sentence_key``` is tweet\n",
    "\n",
    "The argument:\n",
    "- `truncation=True`: This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model.\n",
    "\n",
    "Why did I tokenize first?\n",
    "-  because its better to tokenize first then oversample and undersample, and also need to train test plit\n",
    "- so don't need to retokenizing the same tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1679670111608,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "FPT_obn3VBmK",
    "outputId": "dda8cf60-9826-4537-cf25-8c774e849e44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                    \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['count', 'hate_speech_count', 'offensive_language_count', 'neither_count', 'class', 'tweet', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 24783\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pre process function for existing data from dataset library\n",
    "def preprocess_function(examples):\n",
    "  return tokenizer(examples[\"tweet\"], truncation=True)\n",
    "\n",
    "# #preprocessing on hate_speech dataset\n",
    "# def my_preprocess_function(examples):\n",
    "#   return tokenizer(examples, truncation=True)\n",
    "\n",
    "#encoded hate_speech for fine tuning\n",
    "# endocded_hspeech = hate_speech[\"tweet\"].map(my_preprocess_function)\n",
    "\n",
    "encoded_ds = hate_speech_ds.map(preprocess_function)\n",
    "\n",
    "#check what encoded ds looks like\n",
    "encoded_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "32aRlTWga_LS"
   },
   "outputs": [],
   "source": [
    "hate_speech_df = pd.DataFrame(encoded_ds[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "zyx-9J8R3cP-"
   },
   "outputs": [],
   "source": [
    "# hate_speech_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fosphpGTd_Bv"
   },
   "source": [
    "### Undersampling and Oversampling\n",
    "\n",
    "1. Defining the tokenizer (tokenizer is a method or process to convert the words into numbers such that the computer can understand it)\n",
    "2. sample of the tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFXa1VPMZTJl"
   },
   "source": [
    "\n",
    "\n",
    "Perform oversampling using [Imbalanced-Learn Library](https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/)\n",
    "\n",
    "-  ```minority``` parameter means,  majority of 1,000 examples and the minority class had 100, this strategy would oversampling the minority class so that it has 1,000 examples.\n",
    "\n",
    "- Need to oversample twice becuase we have 3 classes, after the first over sampling only 0.0 has increased  from 2050 to 30333 (same logic applies to oversampling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1679670115064,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "HsPDp6_E-Vyb",
    "outputId": "f02c99c3-cea4-40f2-a7a5-deacd50115e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distrubution before over sampling\n",
      "Counter({1: 19190, 2: 4163, 0: 1430})\n",
      "distrubution after over sampling\n",
      "Counter({1: 19190, 0: 19190, 2: 4163})\n",
      "distrubution after 2nd over sampling\n",
      "Counter({2: 19190, 1: 19190, 0: 19190})\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "X = hate_speech_df[[\"tweet\",'input_ids', 'attention_mask']].values\n",
    "y = hate_speech_df[\"class\"].values\n",
    "\n",
    "print(\"distrubution before over sampling\")\n",
    "print(Counter(y))\n",
    "#d 1,000 examples and the minority class had 100, this strategy would oversampling the minority class so that it has 1,000 examples.\n",
    "oversample = RandomOverSampler(random_state=0,sampling_strategy='minority')\n",
    "\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "print(\"distrubution after over sampling\")\n",
    "print(Counter(y_over))\n",
    "\n",
    "# need to oversample twice becuase we have 3 classes\n",
    "# after the first over sampling only 0.0 has increased  from 2050 to 30333\n",
    "X_over, y_over = oversample.fit_resample(X_over, y_over)\n",
    "print(\"distrubution after 2nd over sampling\")\n",
    "print(Counter(y_over))\n",
    "\n",
    "\n",
    "over_h_speech = pd.DataFrame(X_over, columns=[\"tweet\",'input_ids', 'attention_mask'])\n",
    "over_h_speech[\"label\"] = y_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "k1aVQ16jgT8w"
   },
   "outputs": [],
   "source": [
    "# over_h_speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9ktoI98cGHG"
   },
   "source": [
    "Perform undersampling using [Imbalanced-Learn Library](https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1679670115064,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "rqwboZBucKUx",
    "outputId": "1f67353e-1baf-48d1-a86f-d4d09224e500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distrubution after under sampling\n",
      "Counter({2: 4163, 0: 1430, 1: 1430})\n",
      "distrubution after 2nd under sampling\n",
      "Counter({0: 1430, 1: 1430, 2: 1430})\n"
     ]
    }
   ],
   "source": [
    "undersample = RandomUnderSampler(random_state=0,sampling_strategy='majority')\n",
    "\n",
    "X_under, y_under = undersample.fit_resample(X, y)\n",
    "print(\"distrubution after under sampling\")\n",
    "print(Counter(y_under))\n",
    "\n",
    "X_under, y_under = undersample.fit_resample(X_under, y_under)\n",
    "print(\"distrubution after 2nd under sampling\")\n",
    "print(Counter(y_under))\n",
    "\n",
    "# under_h_speech = pd.DataFrame({\"tweet\":X_under.flatten(),\"class\":y_under})\n",
    "\n",
    "\n",
    "under_h_speech = pd.DataFrame(X_over, columns=[\"tweet\",'input_ids', 'attention_mask'])\n",
    "under_h_speech[\"label\"] = y_over\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRmk9hehjw25"
   },
   "source": [
    "### Train test split on the following:\n",
    "- hate_speech\n",
    "- over_h_speech\n",
    "- under_h_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "-CZFcLDIN8tu"
   },
   "outputs": [],
   "source": [
    "hate_speech_df.columns = ['count', 'hate_speech_count', 'offensive_language_count',\n",
    "       'neither_count', 'label', 'tweet', 'input_ids', 'attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "M-OPvr8bj-O5"
   },
   "outputs": [],
   "source": [
    "\n",
    "train, test = train_test_split(hate_speech_df, test_size=0.2)\n",
    "over_train, over_test = train_test_split(over_h_speech, test_size=0.2)\n",
    "under_train, under_test = train_test_split(under_h_speech, test_size=0.2)\n",
    "\n",
    "\n",
    "                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCzb6ac0lujE"
   },
   "source": [
    "### Create a Dataset Dictionary\n",
    "- So we can use it for the model\n",
    "\n",
    "reference: The `dataset` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set (with more keys for the mismatched validation and test set in the special case of `mnli`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "jPAk-E84l-9p"
   },
   "outputs": [],
   "source": [
    "# Dataset.from_pandas(over_train)\n",
    "\n",
    "\n",
    "\n",
    "train_ds = Dataset.from_pandas(train, split=\"train\")\n",
    "test_ds = Dataset.from_pandas(test, split=\"test\")\n",
    "\n",
    "o_train_ds = Dataset.from_pandas(over_train, split=\"o_train\")\n",
    "o_test_ds = Dataset.from_pandas(over_train, split=\"o_test\")\n",
    "\n",
    "\n",
    "u_train_ds = Dataset.from_pandas(under_train, split=\"u_train\")\n",
    "u_test_ds = Dataset.from_pandas(under_test, split=\"u_test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1679670121847,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "vek29OOTvXIK",
    "outputId": "dfd8389d-55ea-4ccd-f485-edbcfcff2afe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['count', 'hate_speech_count', 'offensive_language_count', 'neither_count', 'label', 'tweet', 'input_ids', 'attention_mask', '__index_level_0__'],\n",
       "    num_rows: 19826\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "LppdmODameD0"
   },
   "outputs": [],
   "source": [
    "\n",
    "#processed dataset\n",
    "dataset_proc = DatasetDict({\"train\":train_ds,\n",
    "                             \"test\":test_ds, \n",
    "                             \"o_train_ds\":o_train_ds,\n",
    "                             \"o_test_ds\":o_test_ds,\n",
    "                             \"u_train_ds\":u_train_ds,\n",
    "                             \"u_test_ds\":u_test_ds, })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "OeV5eLL3wbb1"
   },
   "outputs": [],
   "source": [
    "# dataset_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0cHtpXn3tHL"
   },
   "source": [
    "## Fine-tuning the model\n",
    "\n",
    "1. load the model into cache\n",
    "2. .tocuda() to use gpu [source](https://huggingface.co/docs/transformers/perf_train_gpu_one)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "c7a7c5b5d3954a9a88afa445a764775e",
      "be445e67b10a4a3a9a0ceb0cf30b992c",
      "7731aa1959d54966baf4406c1a8ba863",
      "aaaa912e8aa54fca8ab1ba751364d44d",
      "52eca921fef44509859239976ff5ee14",
      "94b183957bc34dc588cd1af085ec3122",
      "56081959adc640dcb950f256e7609e2d",
      "fdfac8d378cf4b798fa96f86e774352e",
      "df322d52719d488f876cf17980127ac6",
      "b14176a574de4bae9562599ca1498ae8",
      "5ed7c4e1f7304e26b074831a63c7b7e7"
     ]
    },
    "executionInfo": {
     "elapsed": 11286,
     "status": "ok",
     "timestamp": 1679662341347,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "VPSCNjlG3i97",
    "outputId": "dd7f9ef4-8b95-423d-dad9-2ada338cc95a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                     | 41.9M/268M [00:31<02:46, 1.36MB/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = 3\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=labels)\n",
    "##comment this out if you just want cpu\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=labels).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCs_PJ7MxSOd"
   },
   "source": [
    "defining training arguments\n",
    "\n",
    "required attributes\n",
    "-  folder name for model checkpoint storage\n",
    "\n",
    "- evaluation_strategy (str or IntervalStrategy, optional, defaults to \"no\") â€” The evaluation strategy to adopt during training. Possible values are:\n",
    "- per_device_train_batch_size (int, optional, defaults to 8) â€” The batch size per GPU/TPU core/CPU for training.\n",
    "- we can push the model to the Hub regularly during training. Remove it if you didn't follow the installation steps at the top of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESW7nnEKM3wy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vToFIEmC3i_8"
   },
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "batch_size= 8\n",
    "metric_name = \"accuracy\"\n",
    "task = \"hate_speech\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdAwHN_DypxV"
   },
   "source": [
    "measurement of performance/ prediction \n",
    "1. `metric` we loaded earlier\n",
    "2. the prediction is rgmax of our predicted logits or predictions[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MV__LMZl3vcq"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions[:, 0]\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pb0hgcuuGO7p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4058,
     "status": "ok",
     "timestamp": 1679662705636,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "pmC-tbgk3jCA",
    "outputId": "e7080325-b1eb-4f7c-dafb-17fc05a52850"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/distilbert-base-uncased-finetuned-hate_speech is already a clone of https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "WARNING:huggingface_hub.repository:/content/distilbert-base-uncased-finetuned-hate_speech is already a clone of https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "#define the validation key of sst2\n",
    "validation_key  = \"validation\"\n",
    "trainer = Trainer(model,\n",
    "                  args,\n",
    "                  train_dataset=dataset_proc[\"train\"],\n",
    "                  eval_dataset=dataset_proc[\"test\"],\n",
    "                  tokenizer=tokenizer,\n",
    "                  compute_metrics=compute_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "executionInfo": {
     "elapsed": 784327,
     "status": "ok",
     "timestamp": 1679664859694,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "hPL51L_s3yAT",
    "outputId": "8a2f1e0c-06ff-4420-e9d3-b49c96b2e0e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6200' max='6200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6200/6200 13:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.294211</td>\n",
       "      <td>0.056082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.294211</td>\n",
       "      <td>0.056082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.188300</td>\n",
       "      <td>0.294211</td>\n",
       "      <td>0.056082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.294211</td>\n",
       "      <td>0.056082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.294211</td>\n",
       "      <td>0.056082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 784.05\n",
      "Samples/second: 126.43\n",
      "GPU memory occupied: 9937 MB.\n"
     ]
    }
   ],
   "source": [
    "result = trainer.train()\n",
    "print_summary(result)\n",
    "#why is the training and loss and accuracy all the same?\n",
    "\n",
    "# print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKF7P4vJA6_b"
   },
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 8963,
     "status": "ok",
     "timestamp": 1679664868652,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "WJFeNDFM3yEY",
    "outputId": "02007a15-cbd0-46a9-e32a-5ee150045852"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='310' max='310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [310/310 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.29421094059944153,\n",
       " 'eval_accuracy': 0.0560823078474884,\n",
       " 'eval_runtime': 9.5234,\n",
       " 'eval_samples_per_second': 520.508,\n",
       " 'eval_steps_per_second': 32.551,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 15323,
     "status": "ok",
     "timestamp": 1679664883973,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "CSQDumKQTdwx",
    "outputId": "393ee0b0-e8af-492f-9876-e76312eb9e62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech\n",
      "   5dc7512..8b3f0f8  main -> main\n",
      "\n",
      "WARNING:huggingface_hub.repository:To https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech\n",
      "   5dc7512..8b3f0f8  main -> main\n",
      "\n",
      "To https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech\n",
      "   8b3f0f8..bd3a48b  main -> main\n",
      "\n",
      "WARNING:huggingface_hub.repository:To https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech\n",
      "   8b3f0f8..bd3a48b  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech/commit/8b3f0f829c7a6acf7c198dea9b0ba000532167ca'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1679664883973,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "YdCQESK3Tdzg",
    "outputId": "a69be3c2-4d52-4847-9d8e-87968e978b8d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'distilbert-base-uncased-finetuned-hate_speech'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{model_name}-finetuned-{task}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GLqcA-7Td12"
   },
   "outputs": [],
   "source": [
    "# how to share the model you created\n",
    "\n",
    "AutoModelForSequenceClassification.from_pretrained(\"Dc26/distilbert-base-uncased-finetuned-hate_speech\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go0I7MsaL8j6"
   },
   "source": [
    "## Hyperparameter search\n",
    "\n",
    "install optuna and raytune cause it's used for hyper parameter tuning\n",
    "\n",
    "we also defined a new model using the ```new_model```, so we create a new model every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Au50QuA6L85W"
   },
   "outputs": [],
   "source": [
    "num_labels=3\n",
    "def new_model():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4008,
     "status": "ok",
     "timestamp": 1679665940172,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "f8m3I9xVL87-",
    "outputId": "e0a71cd7-c5b2-423b-cabe-5092ccddfec5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/content/distilbert-base-uncased-finetuned-hate_speech is already a clone of https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "WARNING:huggingface_hub.repository:/content/distilbert-base-uncased-finetuned-hate_speech is already a clone of https://huggingface.co/Dc26/distilbert-base-uncased-finetuned-hate_speech. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=new_model,\n",
    "    args=args,\n",
    "    train_dataset=dataset_proc[\"train\"],\n",
    "    eval_dataset=dataset_proc[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OaOs8EdZE-W"
   },
   "source": [
    "hyperparameter search  may take a long time to run on the full dataset so \n",
    "- it only runs on 1/10th of the dataset\n",
    "- only train the full dataset on the best perfoming one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0ipxlg7L8-f"
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset_proc[\"train\"].shard(index=1, num_shards=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 991
    },
    "executionInfo": {
     "elapsed": 2202,
     "status": "error",
     "timestamp": 1679665954400,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "l-kotbZbL9Aw",
    "outputId": "eeb2c7b8-6e49-46e5-bc0f-e11c761dfaca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-24 13:52:31,865]\u001b[0m A new study created in memory with name: no-name-ff8d76f1-4d8e-4de7-8c98-6d7d79c9d77e\u001b[0m\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[33m[W 2023-03-24 13:52:33,279]\u001b[0m Trial 0 failed with parameters: {'learning_rate': 2.7358513247381042e-05, 'num_train_epochs': 1, 'seed': 6, 'per_device_train_batch_size': 32} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 14.75 GiB total capacity; 13.65 GiB already allocated; 4.81 MiB free; 13.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/integrations.py\", line 187, in _objective\n",
      "    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\", line 1627, in train\n",
      "    self._move_model_to_device(self.model, args.device)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\", line 716, in _move_model_to_device\n",
      "    model = model.to(device)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/modeling_utils.py\", line 1811, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 989, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 641, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 664, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 987, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 14.75 GiB total capacity; 13.65 GiB already allocated; 4.81 MiB free; 13.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[33m[W 2023-03-24 13:52:33,281]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-5671481c44c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# returns Best Run object which mazimizes the accuracy/ desired metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameter_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mhyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m   2536\u001b[0m             \u001b[0mHPSearchBackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWANDB\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_hp_search_wandb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m         }\n\u001b[0;32m-> 2538\u001b[0;31m         \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_search_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/integrations.py\u001b[0m in \u001b[0;36mrun_hp_search_optuna\u001b[0;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_jobs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBestRun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/integrations.py\u001b[0m in \u001b[0;36m_objective\u001b[0;34m(trial, checkpoint_dir)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0;31m# If there hasn't been any evaluation during the training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_reloaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_model_on_device\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1627\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_wrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;31m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tie_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1809\u001b[0m             )\n\u001b[1;32m   1810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1811\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    985\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    986\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 987\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 14.75 GiB total capacity; 13.65 GiB already allocated; 4.81 MiB free; 13.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# returns Best Run object which mazimizes the accuracy/ desired metric\n",
    "best_run = trainer.hyperparameter_search(n_trials=5, direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1hRCnFgL9Cp"
   },
   "outputs": [],
   "source": [
    "# best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOgeUHo6ZrB7"
   },
   "source": [
    "You can customize the objective to maximize by passing along a `compute_objective` function to the `hyperparameter_search` method, and you can customize the search space by passing a `hp_space` argument to `hyperparameter_search`. See this [forum post](https://discuss.huggingface.co/t/using-hyperparameter-search-in-trainer/785/10) for some examples.\n",
    "\n",
    "To reproduce the best training, just set the hyperparameters in your `TrainingArgument` before creating a `Trainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGU6am0HZrUu"
   },
   "outputs": [],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "    setattr(trainer.args, n, v)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttVZ_PZf5RnY"
   },
   "source": [
    "check if the model workds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1679671174516,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "gGRzhnI35R1Q",
    "outputId": "07376cc2-dae2-4b6f-83e6-75fce6d8fc8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15324\n",
       "2    3376 \n",
       "0    1126 \n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1679667714207,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "qT_Sqiy25Ug-",
    "outputId": "68394241-3147-4156-ee38-2bb879c5b546"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3841\n",
       "2    824 \n",
       "0    292 \n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1663,
     "status": "ok",
     "timestamp": 1679671791219,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "5IEJx3ETAuCp",
    "outputId": "cb887310-4b93-41cb-a073-7fca8f0c0009"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='0'\n",
    "\n",
    "current_model = AutoModelForSequenceClassification.from_pretrained(\"Dc26/distilbert-base-uncased-finetuned-hate_speech\")\n",
    "pipe = TextClassificationPipeline(model=current_model, tokenizer=tokenizer, return_all_scores=False)\n",
    "\n",
    "\n",
    "def get_prediction(text):\n",
    "  return pipe(text)[-1][\"label\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 367902,
     "status": "ok",
     "timestamp": 1679672159114,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "s--csHxMAuI-",
    "outputId": "bf919624-0eb3-410c-813f-ae407042fa85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 55s, sys: 737 ms, total: 5min 56s\n",
      "Wall time: 6min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test[\"predicted\"] = test[\"tweet\"].apply(lambda x: get_prediction(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1679672159115,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "8TEBtSUTJm4e",
    "outputId": "ca09f1f4-d674-4e09-a872-8e7e21b94258"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c6abca82-f35c-4e35-b616-1b68d047175e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177</td>\n",
       "      <td>3724</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>77</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6abca82-f35c-4e35-b616-1b68d047175e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c6abca82-f35c-4e35-b616-1b68d047175e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c6abca82-f35c-4e35-b616-1b68d047175e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "label        0     1    2\n",
       "predicted                \n",
       "0          87   65    3  \n",
       "1          177  3724  47 \n",
       "2          40   77    737"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create a confusion matrix\n",
    "test[\"predicted\"] = test[\"predicted\"].astype(int)\n",
    "test.groupby([\"predicted\", \"label\"]).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1679673079886,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "wFnvtawOUD4D",
    "outputId": "d951edd2-cd80-43b2-8c45-ec59da117f0b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9285367e-2024-43ac-bb62-982ea9e21c71\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177</td>\n",
       "      <td>3724</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>77</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9285367e-2024-43ac-bb62-982ea9e21c71')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9285367e-2024-43ac-bb62-982ea9e21c71 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9285367e-2024-43ac-bb62-982ea9e21c71');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "label        0     1    2\n",
       "predicted                \n",
       "0          87   65    3  \n",
       "1          177  3724  47 \n",
       "2          40   77    737"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "test.groupby([\"predicted\", \"label\"]).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1679672159115,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "MEQK3YAQLXXF",
    "outputId": "24c56f8c-65dc-456f-b467-22d375afddf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3948\n",
       "2    854 \n",
       "0    155 \n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"predicted\"].value_counts()\n",
    "# cause tpp much 2 data predicted everything as 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1679673006929,
     "user": {
      "displayName": "Diane Cruz",
      "userId": "05838927147744389195"
     },
     "user_tz": -480
    },
    "id": "jmByfJ9fKxYE",
    "outputId": "a790f59d-45f6-4c8a-eef2-c6e12a15a490"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.917490417591285"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test[\"predicted\"]==test[\"label\"]].shape[0] / test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1680098588743,
     "user": {
      "displayName": "Diane Kathryn Cruz",
      "userId": "08869112525818712386"
     },
     "user_tz": -480
    },
    "id": "IMfof5x5MQ5S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKSkHlmMAMZ4"
   },
   "source": [
    "## Reccomendation\n",
    "\n",
    "1. Further data cleaning\n",
    "  - looking at the tweets since there are a lot of emojis so, maybe the performance could have been better if we remove emojis and done further cleaning\n",
    "  - remove @username and make a generic tag instead of the model seeing different username\n",
    "2.  test on the if the model would be better with the undersampling and over sample datasets\n",
    "3. Graph the confusion matrix of the test set\n",
    "4. Compare performance with an existing paper (papers: https://github.com/aymeam/Datasets-for-Hate-Speech-Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbQWPx-t7r9y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a13584b9f134dfa97ca691f8eddd434": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10f1b68b08f141a8bcbd55adab4e7821": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16ed605b5cb441758581fe9c80ffac1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1de3ef734af54e9084ba6d24ad2b9573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_66631f3e7c72429f8d5d5145f3158676",
       "IPY_MODEL_81011b5150904e2fa994ae7deeb8edae",
       "IPY_MODEL_e5eff094c0644c69ad9e5d3a31a3f452",
       "IPY_MODEL_9c9f7251c0e941e7a63f7f9a8323cfa9",
       "IPY_MODEL_8f1e4282e29643ed8225f2bf1028056f"
      ],
      "layout": "IPY_MODEL_eda9f24f0ff243cfbd6878a75e927d07"
     }
    },
    "210483cad01847e58be29f530e5ee8cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e56946c90214f27a89a16113cea861d",
       "IPY_MODEL_5417a60f28be450a8cc7938dfa12e0a2",
       "IPY_MODEL_46e7cba5323643189a971b32fd0bb809"
      ],
      "layout": "IPY_MODEL_a9adb03db8d04ce9852e852d40cd841f"
     }
    },
    "31d82894dc4a4f8b927e78d00950e39b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32d5648aa6e44e0e96929fc91fc999d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37b872d373cc48bb994ab6d312557c13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46e7cba5323643189a971b32fd0bb809": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32d5648aa6e44e0e96929fc91fc999d5",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7ba70446b54341ccb46d9cb5cc3f4105",
      "value": " 3/3 [00:00&lt;00:00,  9.61it/s]"
     }
    },
    "4983fb7c2cca461fb5539e73cccd6ac7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec953004e4534ac68da1efba05da22b2",
       "IPY_MODEL_fe72c604335b42d895dd3ce73348a057",
       "IPY_MODEL_86149739912d4bf7a46949063be7b2bc"
      ],
      "layout": "IPY_MODEL_10f1b68b08f141a8bcbd55adab4e7821"
     }
    },
    "4e56946c90214f27a89a16113cea861d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd8ddd6f20114f3d8b09b872d27cbc60",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b4831d3b79f449d89495fc7f11f4df93",
      "value": "100%"
     }
    },
    "52eca921fef44509859239976ff5ee14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5417a60f28be450a8cc7938dfa12e0a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bc1ba4b9d2345a98a594a4b05dbc293",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ba6675b2cea34a0c8cb08a39f2844d40",
      "value": 3
     }
    },
    "56081959adc640dcb950f256e7609e2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e5be5a0971640c7b2391691f809da88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ed7c4e1f7304e26b074831a63c7b7e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66631f3e7c72429f8d5d5145f3158676": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85baed07f8c94ed196c374a6e58e22cc",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fcf7279ba53b440abe3896b38ef0cc6f",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "6e45ce4dc1c145468284c1c8c0ec6939": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "7731aa1959d54966baf4406c1a8ba863": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdfac8d378cf4b798fa96f86e774352e",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df322d52719d488f876cf17980127ac6",
      "value": 267967963
     }
    },
    "7ba70446b54341ccb46d9cb5cc3f4105": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7dae63d1f4fb4c8c89725b2d7a8d5f51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81011b5150904e2fa994ae7deeb8edae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_31d82894dc4a4f8b927e78d00950e39b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c55401d4c2c04e7698935c9d8c763355",
      "value": ""
     }
    },
    "85baed07f8c94ed196c374a6e58e22cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86149739912d4bf7a46949063be7b2bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7dae63d1f4fb4c8c89725b2d7a8d5f51",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a222ab21d8c04314918778412ac91e77",
      "value": " 1/1 [00:00&lt;00:00,  8.14it/s]"
     }
    },
    "8f1e4282e29643ed8225f2bf1028056f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37b872d373cc48bb994ab6d312557c13",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_90763fb40fda44dba79088228c7808e0",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "90763fb40fda44dba79088228c7808e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9149d8e855694b8294debd55b71a53d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94b183957bc34dc588cd1af085ec3122": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bc1ba4b9d2345a98a594a4b05dbc293": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c9f7251c0e941e7a63f7f9a8323cfa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_5e5be5a0971640c7b2391691f809da88",
      "style": "IPY_MODEL_6e45ce4dc1c145468284c1c8c0ec6939",
      "tooltip": ""
     }
    },
    "a222ab21d8c04314918778412ac91e77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2925e1f42b04317a660d91d4f622fce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9adb03db8d04ce9852e852d40cd841f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aaaa912e8aa54fca8ab1ba751364d44d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b14176a574de4bae9562599ca1498ae8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5ed7c4e1f7304e26b074831a63c7b7e7",
      "value": " 268M/268M [00:01&lt;00:00, 187MB/s]"
     }
    },
    "b14176a574de4bae9562599ca1498ae8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4831d3b79f449d89495fc7f11f4df93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b984373baa084d959c74f810100f3a67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba6675b2cea34a0c8cb08a39f2844d40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "be445e67b10a4a3a9a0ceb0cf30b992c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94b183957bc34dc588cd1af085ec3122",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_56081959adc640dcb950f256e7609e2d",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "c55401d4c2c04e7698935c9d8c763355": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5d3dd1626674485b1665c78e64d7510": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7a7c5b5d3954a9a88afa445a764775e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_be445e67b10a4a3a9a0ceb0cf30b992c",
       "IPY_MODEL_7731aa1959d54966baf4406c1a8ba863",
       "IPY_MODEL_aaaa912e8aa54fca8ab1ba751364d44d"
      ],
      "layout": "IPY_MODEL_52eca921fef44509859239976ff5ee14"
     }
    },
    "dd8ddd6f20114f3d8b09b872d27cbc60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df322d52719d488f876cf17980127ac6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e5eff094c0644c69ad9e5d3a31a3f452": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_c5d3dd1626674485b1665c78e64d7510",
      "style": "IPY_MODEL_0a13584b9f134dfa97ca691f8eddd434",
      "value": true
     }
    },
    "ec953004e4534ac68da1efba05da22b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2925e1f42b04317a660d91d4f622fce",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b984373baa084d959c74f810100f3a67",
      "value": "100%"
     }
    },
    "eda9f24f0ff243cfbd6878a75e927d07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "fcf7279ba53b440abe3896b38ef0cc6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdfac8d378cf4b798fa96f86e774352e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe72c604335b42d895dd3ce73348a057": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9149d8e855694b8294debd55b71a53d1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_16ed605b5cb441758581fe9c80ffac1d",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
